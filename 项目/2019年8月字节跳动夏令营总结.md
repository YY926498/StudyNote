# 2019年8月字节跳动夏令营总结

很幸运，偶然的机会下看到字节跳动夏令营的通知，赶上了第二批笔试的末班车，然后靠着免面试，侥幸通过了选拔。在确定入营后，hr发布了项目列表，由于只会一点C++和网络的知识，适合我的题目有：高并发秒杀系统和基于消息队列的中间件设计。考虑之后，选择了高并发秒杀系统。

要求是：每个小组5台服务器，商品数据量几十G，用户ID与sessionid映射表几十M。

等到mentor分享了一些topic后，才发现这个题目跟我所想的完全不同:cry:。整个流程是给出5个接口，分别是：查询商品、下订单、支付、订单校验和重置接口。

由于我没学过http和数据库相关的东西，并且另外两个队友都熟悉JAVA，并且一个队友做过相关开发，就决定使用JAVA作为开发语言。我负责redis部分。

来到夏令营后，跟mentor详细沟通后，发现服务器内存放不下整个商品数据，因此考虑使用mysql存储商品数据。另外由于有5台服务器，为了充分压榨服务器的性能，采用nginx进行负载均衡，同时为了提高qps，采用redis，考虑到高可用，采用redis的集群模式。将商品数据存放在mysql中。为了提高读写速度，采用读写分离，分表等操作。为了提升速度，不做持久化操作，因此mysql只负责存放商品信息。

确定大概方向后，我就开始数据应该如何存放。由于要考抢购时，有人会使用脚本或者黄牛开多个小号等作弊行为，因此需要设立黑名单。最开始的策略是单独拿出一台服务器，开一个redis实例作为验证数据库。这个redis主要存放sessionid和uid的映射和黑名单。由于redis是key-value数据库，因此非常方便。另外四台服务器起redis集群，每台服务器开两个redis实例，利用官方工具，形成四主四从模式，主要存放商品信息、订单等数据。

黑名单策略：

1. 首先验证请求的uid与sessionid是否对应。如果不满足映射，就将uid和IP地址放入下面说的黑名单中，同时返回403。
2. 建立两个set，分别是"cheat:IP"和"cheat:uid"。其中"cheat:IP"放加入黑名单的IP地址，"cheat:uid"放加入黑名单的uid。在通过uid和sessionid的映射验证后，在这两个set查询，如果uid或者IP已经上了黑名单，就直接返回403。
3. 查找uid和IP在当前时间段的写请求次数，具体做法时获取当前时间戳，然后除以时间周期，我们暂定为1s。这样方便快速查找，但这样会有一个缺陷，就是如果用户或者IP地址在这1秒钟的最后发起多次请求，然后在下1秒的刚开始时，发起多次请求，这样就不会被加入黑名单，另一种做法是参考TCP的滑动窗口。但是这样比较复杂，需要将用户发起请求的时间戳记录下来，放在有序列表里。因此采用时间片的方法来做。key的名字是"time:uid:"+时间戳和"time:IP:"+时间戳。这是一个set，每次来请求就直接查询set中是否已经存在该用户或者IP。同时为了减少内存的使用，给每个key设置过期时间，过期时间暂定为为2s钟。
4. 如果在"time:uid:"+时间戳或者"time:IP:"+时间戳中已经存在，则对"count:uid"和"count:IP"中对应的uid和IP进行自增操作，如果uid或者IP在当前时间片中的写请求次数达到阈值，就加入到黑名单中。如果不存在与于"time:uid"或者"time:IP"中，就在"count:uid"或"count:IP"中将对应项置1。其中"count:uid"和"count:IP"为哈希表。

上面就是大部分的黑名单策略。

查询商品操作:

1. 首先经过上述的黑名单验证，如果通过，则进入下一步，否则返回403。
2. 在redis集群中查询商品详情，如果redis中不存在该商品，就去mysql查询商品信息，如果查询到商品信息后，存入redis集群中，并设置过期时间，第一次设置的是30s，后来发现太短了，会频繁查询mysql，因此将时间设置为10min左右。如果mysql中没有该商品数据，则认为该用户作弊，将uid和IP地址分别放入"cheat:uid"和"cheat:IP"中，并返回403。

下订单操作：

1. 首先经过黑名单验证，如果通过，则进入下一步，否则返回403。
2. 查询商品信息，如果查到商品信息，进入下一步，否则返回403。
3. 由于集群模式，为了避免超卖，需要加锁，我们选择在redis中加锁。加锁规则后面讲。获取到锁后，查询"order:pid:"+pid的成员，其中"order:pid:"+pid为set。如果该集合中已经有该用户，则认为该用户频繁下单，加入黑名单。并且查询"order:pid:"+pid的成员数量，如果超过商品数量，则返回下单失败。下单失败后，均要释放锁。
4. 如果商品剩余数量大于1，就下订单。为了保证订单号唯一，同时根据订单号还要反映出pid和时间。因此订单号设置为uid+"~"+pid+"~"+时间戳/1000。下单完成后，释放锁。将该uid加入到"order:pid:"+pid集合中，并且把pid和订单号加入到"order:uid:"+uid哈希表中，这是为了方便后边支付操作。

支付操作：

1. 首先经过黑名单验证，如果通过，则进入下一步，否则返回403。
2. 验证价格与实际商品价格是否一致，如果不一致，将用户及IP地址加入黑名单，同时返回403，否则进入下一步。
3. 查询订单列表"order:pid:"+pid中是否有该用户，如果没有，将该用户和IP地址加入黑名单，同时返回403。如果有，则将该商品和订单号加入"pay:uid:"+uid哈希集合中其中订单号后面需要加入token，方便后面验证，同时删除"order:uid:"+uid中的订单。返回结果。

校验操作：

1. 跟据uid参数，取出"order:uid:"+uid和"pay:uid:"+uid所有成员，然后根据pid进行排序，同时将订单号、支付状态码、token等分割出来，然后返回

重置操作:

1. 对于所有"order"和"pay"等key，每次生成的时候，都加入到"reset"集合中，在最后的时候，遍历reset集合，将所有key删除。



经验总结：

1. 刚开始是1台服务器单独一个redis负责验证，其余4台开redis集群，后来发现单独的那一台对内存的利用率不高，因此5台服务器开redis集群，，提升性能。但是在后面的重置操作时，最开始时设想直接flush，但是java的jedis没有这个操作了，因此手动记录key，然后遍历。幸好，每次重置操作的时间很长，能够删除完。
2. 关于商品数据的过期时间，最开始设定是30s，发现很容易过期，因此不断延长

可以优化的点：事后经过mentor的讲解，可以从以下几点来进行优化：

1. 将商品信息进行压缩，全部放在内存，有程序自身管理，避免连接redis等开销。
2. 调整nginx的配置，加快处理速度。