# ZooKeeper分布式过程协同技术详解

## ZooKeeper的概念和基础

### 简介

ZooKeeper提供一组简单的API，使得开发人员可以实现通用的协作任务，包括选举主节点、管理组内成员、管理元数据等。ZooKeeper的服务组件运行在一组专用服务器之上，保证了高容错性和可扩展性。

决定使用ZooKeeper来设计应用时，最好将应用数据和协同数据独立开。

#### ZooKeeper的使命

可以在分布式系统中协作多个任务。一个协作任务是指一个包含多个进程的任务。这个任务可以是为了协作或者是为了管理竞争。协作意味着多个进程需要一同处理某些事情，一些进程采取某些行动使得其他进程可以继续工作。竞争指的是两个进程不能同时处理工作的情况。一个进程必须等待另一个进程。

协同并不总是采取像群首选举或者加锁等同步原语的形式。配置元数据也是一个进程通知其他进程需要做什么的一种常用方式。

ZooKeeper客户端API功能强大，包括：

-   保障强一致性、有序性和持久性
-   实现通用的同步原语的能力
-   在实际分布式系统中，并发往往导致不正确的行为。ZooKeeper提供了一种简单的并发处理机制



使用一个独立的协调组件有几个重要的好处：

-   可以独立地设计和实现该组件，这样独立的组件可以跨多个应用共享
-   系统架构师可以简化协作方面的工作
-   系统可以独立地运行和协作这些组件，独立这些组件，简化生产环境中解决实际问题的任务

ZooKeeper使用共享存储模型来实现应用间的协作和同步原语。对于共享存储本身，又需要在进程和存储间进行网络通信。网络通信的是分布式系统中并发设计的基础。

在真实的系统中，需要注意一下问题：

-   消息延迟：消息传输可能发生任意延迟。这种任意延迟可能会导致不可预期的后果。
-   处理器性能：操作系统的调度和超载也可能导致消息处理的任意延迟。
-   时钟偏移：使用时间概念的系统并不少见，时间可能会发生任意的偏移。因此，依赖处理器时钟也许会导致错误的决策。

#### 示例：主-从应用

一般在主-从应用架构中，主节点负责跟踪从节点状态和任务的有效性，并分配任务到从节点。要实现主-从模式的系统，必须解决如下三个关键问题：

-   主节点崩溃：如果主节点发送错误并失效，系统将无法分配新的任务或重新分配已失败的任务。
-   从节点崩溃：如果从节点崩溃，已分配的任务将无法完成。
-   通信故障：如果主节点和从节点之间无法进行信息交换时，从节点将无法得知新任务分配给它。

主节点失效时，需要有一个备份的主节点(backup master)。当主要主节点(primary master)崩溃时，备份主节点接管主要主节点的角色，进行故障转移。此时不是简单开始处理进入主节点的请求。新的主要主节点需要能够恢复到旧的主要主节点崩溃时的状态。对于主节点状态的可恢复性，不能依靠已经崩溃的主节点来获取这些信息，而需要从其他地方获取，即通过ZooKeeper来获取。

另外还有由于网络延迟、网络分区导致脑裂的情况。

**脑裂**：系统中两个或多个部分开始独立工作，导致整体行为不一致性。

需要找出一种处理主节点失效的情况，更重要的是需要避免发生脑裂的情况。

从节点失效：客户端向主节点提交任务后，主节点将任务派发到有效的从节点中。从节点接收到派发的任务，执行完这些任务后会向主节点报告执行状态，主节点下一步会将执行结果通知给客户端。

如果从节点崩溃，主节点需要具有检测从节点崩溃的能力。主节点必须能够检测到从节点的崩溃，并确认哪些从节点是否有效以便派发崩溃节点的任务。一个从节点崩溃时，可以执行了部分任务，也可能全部执行完，但没有报告结果。如果整个运算过程中发生了其他作用，还有必要执行某个恢复过程来清除之前的状态。

通信故障：如果一个从节点与主节点的网络连接断开，比如网络分区导致，重新分配一个任务可能会导致两个从节点执行相同的任务。如果一个任务允许多次执行，在进行任务再分配时可以不用验证第一个从节点是否完成了该任务。如果一个任务不允许，那么应用需要适应多个从节点执行相同任务的可能性。通信故障导致的另一个重要问题是对锁等同步原语的影响。

### 了解ZooKeeper

ZooKeeper暴露一部分调用方法组成的类似文件系统的API，帮助应用构建自己的原语。

通常使用recipes表示原语的实现。包括ZooKeeper操作和维护一个小型的数据节点，这些节点称为znode，采用类似于文件系统的层级树结构进行管理。

针对一个znode，没有数据常常表达了重要的信息。

#### API概述

znode节点可能含有数据，也可能没有。如果一个znode节点包含任何数据，那么数据存储为字节数组。ZooKeeper并不直接提供解析的支持。

ZooKeeper的API暴露了一下方法：

`create /path data`

​	创建一个名为`/path`的znode节点，并包含数据`data`

`delete /path`

​	删除名为`/path`的znode

`exists /path`

​	检查是否存在名为`/path`的节点，在3.6中没有该命令，可以用`stat /path`查看znode的信息

`setData /path data`

​	设置名为`/path`的znode的数据为data，在3.6中好像是`set /path “data”`

`getData /path`

​	返回名为`/path`节点的数据信息

`getChildren /path`

​	返回`/path`节点的所有子节点列表，在3.6中为`get /path`

ZooKeeper不允许局部写入或读取znode节点的数据。

ZooKeeper客户端连接到ZooKeeper服务，通过API调用来建立会话`session`。

#### znode的不同类型

**持久节点和临时节点**

持久的znode只能通过调用`delete`来进行删除。

临时的znode节点在一下两种情况下会被删除：

-   当创建该节点的客户端的会话因超时或主动关闭而中止时
-   当某个客户端（不一定是创建者）主动删除该节点

当前不允许临时节点有子节点，但是以后可能会允许。

**有序节点**

一个有序节点被分配唯一一个单调递增的整数。当创建有序节点时，一个序号会被追加到路径之后。

因此znode分为：持久的，临时的，持久有序的和临时有序的。

#### 监视与通知

ZooKeeper采用基于通知`notification`的机制：客户端向ZooKeeper注册需要接收通知的znode，通过对znode设置监视点`watch`来接收通知。监视点是一个单次触发的操作，意即监视点会触发一个通知。为了接收多个通知，客户端必须在每次通知后设置一个新的监视点。

因为通知机制是单次触发的操作，所以在客户端接收一个znode变更操作并设置新的监视点时，znode节点也许发生了新的变化。但不会错过状态的变化。

**通知机制的重要保障：**对同一个znode的操作，先向客户端传送通知，然后再对该节点进行变更。

通知机制是一种异步回调的触发机制。具有如下特性：

-   一次触发
-   发往客户端：watches异步发往客户端，ZooKeeper提供一个顺序保证：在看到watch事件之前绝不会看到变化，这样不同的客户端看到的是一致性的顺序。ZooKeeper会保证次序：在收到观察事件之前，客户端不会看到已经为之设置观察的节点的变动。网络延迟或者其他因素可能会让不同的客户端在不同的时间收到观察时间和更新操作的返回码，但可以确保不同的客户端看到的事情都有一致的次序。
-   为数据设置watch：节点有不同的改动方式，ZooKeeper维护两个观察列表：数据观察和子节点观察。`getData`和`exists`设置数据观察，`getChildren`设置子节点观察。不同的返回数据有不同的观察。
-   时序性和一致性：watcher是在client连接到ZooKeeper服务端的本地维护。当一个client连接到新server，watch将会触发任何session事件，断开连接后不能接收到。当客户端重连，先前注册的watcher将会被重新注册并触发。

#### 版本

每一个znode都有一个版本号，随着每次数据变化而自增。可以使用`stat /path`中的查看具体信息，如果是znode数据变化，则查看`dataVersion`。如果是子节点变化，可以查看`cversion`。

当多个ZooKeeper客户端对同一个znode操作时，版本的使用非常重要。在写入数据时会比较版本号，如果版本号无法匹配，就会使得操作失败。

### ZooKeeper架构

ZooKeeper服务器端运行于两种模式：独立模式`standalone`和仲裁模式`quorum`。

独立模式：一个单独的服务器，ZooKeeper状态无法复制。

仲裁模式：一组ZooKeeper服务器，称为ZooKeeper集合`ZooKeeper ensemble`，可以进行状态的复制，并同时服务客户端的请求。

#### ZooKeeper仲裁

在ZooKeeper中，仲裁也是依据法定人数的方法来确认保证服务器有效运行的服务器最小个数。

#### 会话

在对ZooKeeper集合执行任何请求前，客户端必须先与服务建立会话。客户端提交给ZooKeeper的所有操作均关联在一个会话上。当一个会话因某种原因而中止时，在这个会话期间创建的临时节点将会消失。

如果会话无法与当前连接的服务器继续通信时，会话可能转移到另一个服务器上。ZooKeeper客户端库透明地转移一个会话到不同的服务器。

会话提供顺序保证，但同一个客户端有多个会话时不能保证顺序性。

### 开始使用ZooKeeper

#### 会话的状态和声明周期

会话的生命周期指会话从创建到结束的时期。

主要的可能状态有：CONNECTING、CONNECTED、CLOSED和NOT_CONNECTED。

如果客户端与服务器因超时而断开连接，客户端仍然保持CONNECTING状态。如果因网络分区问题导致客户端与ZooKeeper集合被隔离而发生连接断开，状态一直保持，直到显式地关闭这个会话，或者分区问题修复后，客户端能够获悉ZooKeeper服务器发送的会话已经过期。**客户端只能等待服务端发送会话过期，自己不能声明自己的会话过期。**

创建会话时，设置会话超时参数。经过时间t之后，服务接收不到会话的任何消息，服务就会声明会话过期。客户端在经过$t/3$时间后未收到任何消息，客户端将向服务端发送心跳信息。在经过$2t/3$时间后，客户端开始寻找其他服务器，此时有$t/3$的时间去寻找。

在仲裁模式下，应用需要传递可用的服务器列表给客户端，告知客户端可以连接的服务器信息并选择一个进行连接。

如果连接到一个不同的服务器时，**这个服务器的ZooKeeper状态需要与最后连接的服务器的ZooKeeper状态保持最新**。即客户端不能连接到比它更老的服务器。ZooKeeper通过在服务中排序更新操作来决定状态是否最新。ZooKeeper确保每一个变化相对于所有其他已执行的更新是完全有序的。在ZooKeeper实现中，系统会根据每一个更新建立的顺序来分配给事务标识符`zkid`。

#### ZooKeeper与仲裁模式

启动ZooKeeper集群时，需要在`zoo.cfg`配置文件中加入语句：

~~~sh
server.1=127.0.0.1:2222:2223
server.2=127.0.0.1:3333:3334
server.3=127.0.0.1:4444:4445
~~~

每一个server.n项指定了编号为n的ZooKeeper服务器使用的地址和端口号。每个server.n项通过冒号分隔为三个部分，第一部分为服务器n的IP地址或主机名，第二部分和第三部分为TCP端口号，分别用于仲裁通信和群首选举。

#### 实现一个原语：通过ZooKeeper实现锁

使用ZooKeeper的接口来管理一个znode，以此来实现锁。为了获得一个锁，每个进程p尝试创建znode，名为`/lock`。如果进程p成功创建了znode，就表示它获得了锁并可以继续执行其临界区域的代码。但要注意如果进程崩溃或者网络故障，导致锁无法释放的问题。

因此需要指定`/lock`为临时节点。。

其他进程因znode存在而创建`/lock`失败。因此，进程监听`/lock`的变化，并在检测到`/lock`删除时再次尝试创建节点来获得锁。当收到`/lock`删除的通知时，如果进程p’还需要继续获取锁，它就继续尝试创建`/lock`的步骤，如果其他进程已经创建了，就继续监听节点。

### 一个主-从例子的实现

一般主-从模式的模型包括三个角色：

-   主节点：负责监听新的从节点和任务，分配任务给可用的从节点
-   从节点：从节点通过系统注册自己，以确保主节点看到它们可以执行任务，然后开始监视新任务
-   客户端：创建新任务并等待系统的响应

#### 主节点角色

如果是单ZooKeeper服务器，可以通过创建临时节点当做主节点

~~~sh
create -e /master "主机信息"
~~~

其中`create`的`-e`选项表示创建临时节点

当节点已经创建，再次创建就是失败。考虑到一个活动的主节点可能会崩溃，备份主节点需要接替活动主节点的角色，需要在`/master`节点上设置一个监视点。

~~~sh
stat -w /master//3.6.2版本改为-w选项
~~~

其中`-w`选项表示为`/master`节点放置一个监视点。

当节点的值发生变化时，会进行通知。

~~~sh
WatchedEvent state:SyncConnected type:NodeDataChanged path:/master
~~~

如果备份主节点监视到主节点被删除，需要创建新的主节点

#### 从节点、任务和分配

由于需要监视子节点变化，可以由下列语句实现：

~~~sh
ls -w /works
~~~

这个语句可以监视`/works`目录下所有子节点变化情况

#### 从节点角色

从节点首先在`/works`子节点下创建临时性的znode来通知主节点，并在子节点中使用主机名来标识自己：

~~~sh
create -e /workers/worker1.example.com "worker1.example.com:2224"
~~~

一旦节点创建成功，主节点通过监视器得知节点变化。然后从节点需要创建一个父节点`/assign/worker1.example.com `来接收任务分配，并通过第二个参数为`-w`的`ls`命令来监视这个节点的变化，以便等待新的任务。

~~~sh
//从节点
create -e /workers/worker1.example.com "worker1.example.com:2224"
create /assign/worker1.example.com ""
ls -w /assign/worker1.example.com
~~~

此时，从节点准备就绪，可以接收任务分配。

#### 客户端角色

客户端向系统中添加任务。

~~~sh
create -s /tasks/task- "cmd"
~~~

其中`create`语句的`-s`选项表示顺序。本质为一个队列。

接下来可以利用监视机制，来获得任务的完成情况。

比如可以建立一个`/tasks/task-00000`，然后客户端监视这个节点的子节点变化情况。

当客户端建立该节点后，主节点会收到监视通知，然后获取可用的从节点列表，然后分配这个任务给一个从节点：

~~~sh
create /assign/worker1.example.com/task-00000 ""
~~~

从节点根据监视通知，得知有一个新的任务，然后确认任务列表，然后执行任务。一旦执行完毕，就在`/tasks`中添加一个状态znode：

~~~sh
create /tasks/task-00000/status "done"
~~~

客户端接收到通知，并检查执行结果。检查状态znode的信息，并确认任务的执行结果。

## 使用ZooKeeper进行开发

使用go-zookeeper库进行学习。

文档：https://godoc.org/github.com/samuel/go-zookeeper/zk#pkg-index

GitHub：https://github.com/go-zookeeper/zk

### 建立ZooKeeper会话

~~~go
func Connect(servers []string, sessionTimeout time.Duration, options ...connOption) (*Conn, <-chan Event, error) 
~~~

建立一个新的会话。其中第一个参数为ZooKeeper服务器地址，如果有多个，可依次填写，格式为`IP:PORT`，其中PORT=2181时可省略。第二个参数为会话超时。其中第三个参数为连接选项，是一个函数：

~~~go
type connOption func(c *Conn) 
~~~

支持的函数接口有：

~~~go
func WithDialer(dialer Dialer) connOption
func WithHostProvider(hostProvider HostProvider) connOption
func WithLogger(logger Logger) connOption
func WithLogInfo(logInfo bool) connOption
func WithEventCallback(cb EventCallback)
~~~

如果填写多个ZooKeeper服务器地址，假如当前连接z1，同时注册一个监听子节点的监视器。现在删除杀死z1，此时客户端会自动连接其他服务器。

其中返回值`Conn`代表会话连接。`Event`代表监视器，默认缓冲区为6。

**ZooKeeper管理连接**：ZooKeeper客户端库会监控与服务之间的连接，客户端库会告诉连接之间发生的问题，还会主动尝试重新建立通信。

测试：

~~~go
package main
                               
import (
    "fmt"
    "time"

    "github.com/go-zookeeper/zk"
)

func main() {
    conn, connwatch, err := zk.Connect([]string{"127.0.0.1:2181"}, time.Second)
    if err != nil {
        panic(err)
    }
    defer conn.Close()
    go func() {
        for {
            event := <-connwatch
            fmt.Println("conn watch:", event)
        }
    }()
    for {
    }
}
~~~

如果ZooKeeper服务器在运行，正常输出：

~~~sh
conn watch: {EventSession StateHasSession  <nil> 127.0.0.1:2181}
~~~

如果突然杀死ZooKeeper服务器，输出如下：

~~~sh
conn watch: {EventSession StateConnecting  <nil> 127.0.0.1:2181}
2020/10/05 21:00:21 failed to connect to 127.0.0.1:2181: dial tcp 127.0.0.1:2181: connect: connection refused
~~~

然后再重启ZooKeeper服务器，会重新建立连接。

### 获取管理权

ZooKeeper通过插件式的认证方法提供了每个节点的ACL策略功能，因此，可以限制某个用户对某个znode节点的权限。

例程：

~~~go
package main
                               
import (
    "fmt"
    "os"
    "strconv"
    "time"

    "github.com/go-zookeeper/zk"
)

func main() {
    conn, event, err := zk.Connect([]string{"127.0.0.1:2181"}, time.Second)
    if err != nil {
        panic(err)
    }
    defer conn.Close()
    go func() {
        for cur := range event {
            fmt.Println("conn event:", cur) 
        }
    }()
    children, stat, childevent, err := conn.ChildrenW("/")
    if err != nil {
        panic(err)
    }
    fmt.Println("children:", children, "stat:", *stat, "err:", err)
    childwatch := <-childevent
    fmt.Println("childwatch:", childwatch)
    pid := strconv.Itoa(os.Getpid())
    fmt.Println("cur pid:", pid)
    res, err := conn.Create("/newmaster", []byte(pid), zk.FlagTTL, zk.WorldACL(zk.PermAll))
    if err != nil {
        fmt.Println("create fail:", err)
    }
    fmt.Println("Create res:", res) 
}
~~~

运行ZooKeeper服务器后，连续运行上面的程序三次。然后改变ZooKeeper服务器下根目录的子节点数量，这样三个客户端就会争抢创建`/newmaster`子节点。在调用时需要注意ACL权限。

当一个任务加入队列，主节点需要唤醒并分配任务给一个从节点，从节点需要找出分配给自己的任务，任务完成时，客户端需要及时知道，如果主节点故障，另一个等待中的主节点需要接管主节点工作。如果从节点故障，分配给这个从节点的任务需要分配给其他从节点。

## 处理状态变化

通过监视点，客户端可以对指定的znode节点注册一个通知请求，在发生变化时就会收到一个单次的通知。

### 单次触发器

**事件(Event)**：表示一个znode节点执行了更新操作。

一个**监视点(watch)**表示一个与之关联的znode节点和事件类型组成的单次触发器。当一个监视点被一个事件触发时，就会产生一个通知。通知是注册了监视点的应用客户端收到的事件报告的信息。

当应用程序注册了一个监视点来接收通知，匹配该监视点条件的第一个事件会触发监视点的通知，并且最多触发一次。

客户端设置的监视点与会话关联，如果会话过期，等待中的监视点将会被删除。但是监视点可以跨越不同服务端的连接而保持。当一个ZooKeeper客户端与ZooKeeper服务端的连接断开后连接到集合中的另一个服务器，客户端会发送未触发的监视点列表，在注册监视点时，服务端将要检查已监视的znode节点在之前注册监视点之后是否已经变化，如果znode节点已经发生变化，一个监视点的事件就会被发送给客户端，否则在新的服务端上注册监视点。

**单次触发是否会丢失事件**：一个应用在接收到通知后，，注册另一个监视点时，可能会丢失事件，但是比如通过`getChildren`获取子节点列表时注册监视点，从而保证客户端不会丢失任务。

监视点一旦设置无法移除。要想移除一个监视点，一是触发这个监视点，二是使其会话被关闭或过期。

监视点的操作执行成功后就会为一个znode节点设置一个监视点，如果ZooKeeper的操作因为客户端连接断开而失败，应用需要再次执行这些调用。

### multiop

`multiop`可以原子性地执行多个ZooKeeper的操作，执行过程为原子性，即在`multiop`代码块中的所有操作要不全部成功，要不全部失败。

### 通过监视点代替显式缓存管理

一个高效的方式是客户端本地缓存ZooKeeper的znode节点数据，在需要时使用这些数据，一旦数据发生变化，可以让ZooKeeper通知客户端，客户端更新缓存的数据，监视点可以让客户端在本地缓存一个版本的数据，并在数据发生变化时接收到通知来进行更新。

### 顺序的保障

#### 写操作的顺序

服务端对状态的变化的顺序达成一致，并使用相同的顺序执行状态的更新。不同服务端之间可能在不同时间执行状态变化，因为以不同的速度运行。

#### 读操作的顺序

**隐藏通道**：

-   客户端c1更新了`/z`节点的数据，并收到应答
-   客户端c1通过TCP的直接连接告诉客户端c2，`/z`节点状态发生了变化
-   客户端c2读取`/z`节点的状态，但是在c1更新之前就观察到这个状态

这被称为隐藏通道，因为ZooKeeper并不知道客户端之间额外的通信。应用程序使用ZooKeeper进行所有涉及ZooKeeper状态的通信。

#### 通知的顺序

ZooKeeper对通知的排序涉及其他通知和异步响应，以及对系统状态更新的顺序。

比如：假如有一个znode`/config`，其子节点包含应用配置元数据：`/cpnfig/m1,/config/m2`等等。假如主节点应用进程通过`setData`更新每个znode节点，且不能让客户端只读取到部分更新，一个解决办法是在开始更新这些配置前，主节点先创建一个`/config/invalid`节点，其他需要读取这一状态的客户端会监视`/config/invalid`节点，如果该节点存在就不会读取配置状态，当该节点被删除，就意味着有一个新的有效的配置节点集合可用，客户端可以读取该集合的操作。

另一种方法是使用`multiop`来对`/config/m[1-n]`这些节点原子地执行所有`setData`操作，而不是使用一个znode节点来标识部分修改的状态。

ZooKeeper根据触发通知的状态更新对通知消息进行排序，客户端可以通过这些通知感知到真正的状态变化的顺序。

**活性和安全性**：活性`liveness`会确保系统最终取得进展。新任务和新的从节点的通知只是关于活性的事件的例子。原子更新一组配置节点的例子，主要涉及安全性。对于活性的例子中，通知的传送顺序不是特别重要，只要客户端最终获知这些事件就可以继续，但是为了安全性，不按顺序接收通知，可能会导致不正确的行为。

### 监视点的羊群效应和可扩展性

当发生变化时，ZooKeeper会触发一个特定的znode节点的变化导致的所有监视点的集合。如果有1000个客户端通过`exists`操作监视这个znode节点，当znode节点创建后会发送1000个通知，因而被监视的znode节点的一个变化为产生一个尖峰的通知，该尖峰可能带来影响。比如操作延迟。建议在使用ZooKeeper时，避免在一个特定节点设置大量的监视点，最好每次在特定的znode节点上，只有少量的客户端设置监视点，理想情况下最多只设置一个。

比如抢锁：

-   所有进程都尝试创建`/lock`节点，未抢到锁的监视`/lock`节点的删除事件。
-   所有进程创建一个`/lock/lock-xxx`的有序节点，客户端通过`/getChildren`方法获取所有`/lock`下的子节点，如果自身是最小的序号，代表抢到锁，否则就监视前一个节点。比如有`/lock/lock-1`、`/lock/lock-2`和`/lock-lock-3`。其中`/lock-1`抢到锁，`/lock-2`监视`/lock-1`，`/lock-3`监视`/lock-2`。这样每个节点上设置的监视点只有最多一个客户端。

设置一个监视点可能会使服务端的监视点管理器的内存消耗增加250-300字节，因此需要注意设置的监视点数量。

## 故障处理

### 可恢复的故障

ZooKeeper呈现给使用某些状态的所有客户端进程一致性的状态视图。当一个客户端从ZooKeeper获得响应时，客户端可以非常肯定这个响应信息与其他响应信息或其他客户端所接收的响应均保持一致性。

如果客户端与服务器失联，客户端库会积极尝试重新连接另一个ZooKeeper服务器，直到最终重新建立一个会话。一旦会话重新建立，ZooKeeper会产生一个`SyncConnected`事件，并开始处理请求。ZooKeeper还会注册之前已经注册过的监视点，并对失去连接的这段时间发生的变更产生监视点事件。

**当一个进程失去连接后就无法收到ZooKeeper的更新通知。**因此，一个进程可能会在会话丢失时错过某些重要的状态变化。

当整个ZooKeeper集合停机时，时间冻结。当整个集合恢复后，会话的超时时间被重置，客户端回到之前的正确状态，进程不用额外地重启延长时间。

**已存在的监视点与Disconnected事件**

为了使连接断开与重现建立会话之间更加平滑，ZooKeeper客户端会在新的服务器上重新建立所有已存在的监视点。当客户端连接ZooKeeper服务器，客户端会发送监视点列表和最后已知的zxid(最终状态的时间戳)，服务器会接受这些监视点并检查znode节点的修改时间戳与这些监视点是否对应，如果任何已经监视的znode节点的修改时间戳晚于最后已知的zxid，服务器就会触发这个监视点。

每个ZooKeeper操作都完全符合逻辑，除了`exists`。因为`exists`操作与其他操作不同，因为这个操作可以在一个不存在的节点上设置监视点。举例：

如果客户端c1往服务器监视`/events`节点是否存在，此时不存在，然后断开连接操作，客户端c2往服务器创建`/events`节点，然后又删除该节点，客户端c1又重新连接，此时`/events`节点还是不存在，无法触发事件。针对这种情况，应尽量监视存活期更长的znode节点。

**自动重连处理危害**

有些ZooKeeper的封装库通过简单的补发命令自动处理连接丢失的故障，有些情况下可以接受，但有些情况下可能会导致错误的结果。比如`/leader`节点用来建立领导权，程序在执行`create`操作建立`/leader`节点时连接丢失，而盲目地重试`create`操作会导致第二个`create`操作执行失败，因为`/leader`节点已经存在，因此该进程就会假设其他进程获得了领导权。此时应该可以识别并处理这种情况。

### 不可恢复的故障

