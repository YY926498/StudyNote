# ZooKeeper分布式过程协同技术详解

## ZooKeeper的概念和基础

### 简介

ZooKeeper提供一组简单的API，使得开发人员可以实现通用的协作任务，包括选举主节点、管理组内成员、管理元数据等。ZooKeeper的服务组件运行在一组专用服务器之上，保证了高容错性和可扩展性。

决定使用ZooKeeper来设计应用时，最好将应用数据和协同数据独立开。

#### ZooKeeper的使命

可以在分布式系统中协作多个任务。一个协作任务是指一个包含多个进程的任务。这个任务可以是为了协作或者是为了管理竞争。协作意味着多个进程需要一同处理某些事情，一些进程采取某些行动使得其他进程可以继续工作。竞争指的是两个进程不能同时处理工作的情况。一个进程必须等待另一个进程。

协同并不总是采取像群首选举或者加锁等同步原语的形式。配置元数据也是一个进程通知其他进程需要做什么的一种常用方式。

ZooKeeper客户端API功能强大，包括：

-   保障强一致性、有序性和持久性
-   实现通用的同步原语的能力
-   在实际分布式系统中，并发往往导致不正确的行为。ZooKeeper提供了一种简单的并发处理机制



使用一个独立的协调组件有几个重要的好处：

-   可以独立地设计和实现该组件，这样独立的组件可以跨多个应用共享
-   系统架构师可以简化协作方面的工作
-   系统可以独立地运行和协作这些组件，独立这些组件，简化生产环境中解决实际问题的任务

ZooKeeper使用共享存储模型来实现应用间的协作和同步原语。对于共享存储本身，又需要在进程和存储间进行网络通信。网络通信的是分布式系统中并发设计的基础。

在真实的系统中，需要注意一下问题：

-   消息延迟：消息传输可能发生任意延迟。这种任意延迟可能会导致不可预期的后果。
-   处理器性能：操作系统的调度和超载也可能导致消息处理的任意延迟。
-   时钟偏移：使用时间概念的系统并不少见，时间可能会发生任意的偏移。因此，依赖处理器时钟也许会导致错误的决策。

#### 示例：主-从应用

一般在主-从应用架构中，主节点负责跟踪从节点状态和任务的有效性，并分配任务到从节点。要实现主-从模式的系统，必须解决如下三个关键问题：

-   主节点崩溃：如果主节点发送错误并失效，系统将无法分配新的任务或重新分配已失败的任务。
-   从节点崩溃：如果从节点崩溃，已分配的任务将无法完成。
-   通信故障：如果主节点和从节点之间无法进行信息交换时，从节点将无法得知新任务分配给它。

主节点失效时，需要有一个备份的主节点(backup master)。当主要主节点(primary master)崩溃时，备份主节点接管主要主节点的角色，进行故障转移。此时不是简单开始处理进入主节点的请求。新的主要主节点需要能够恢复到旧的主要主节点崩溃时的状态。对于主节点状态的可恢复性，不能依靠已经崩溃的主节点来获取这些信息，而需要从其他地方获取，即通过ZooKeeper来获取。

另外还有由于网络延迟、网络分区导致脑裂的情况。

**脑裂**：系统中两个或多个部分开始独立工作，导致整体行为不一致性。

需要找出一种处理主节点失效的情况，更重要的是需要避免发生脑裂的情况。

从节点失效：客户端向主节点提交任务后，主节点将任务派发到有效的从节点中。从节点接收到派发的任务，执行完这些任务后会向主节点报告执行状态，主节点下一步会将执行结果通知给客户端。

如果从节点崩溃，主节点需要具有检测从节点崩溃的能力。主节点必须能够检测到从节点的崩溃，并确认哪些从节点是否有效以便派发崩溃节点的任务。一个从节点崩溃时，可以执行了部分任务，也可能全部执行完，但没有报告结果。如果整个运算过程中发生了其他作用，还有必要执行某个恢复过程来清除之前的状态。

通信故障：如果一个从节点与主节点的网络连接断开，比如网络分区导致，重新分配一个任务可能会导致两个从节点执行相同的任务。如果一个任务允许多次执行，在进行任务再分配时可以不用验证第一个从节点是否完成了该任务。如果一个任务不允许，那么应用需要适应多个从节点执行相同任务的可能性。通信故障导致的另一个重要问题是对锁等同步原语的影响。

### 了解ZooKeeper

ZooKeeper暴露一部分调用方法组成的类似文件系统的API，帮助应用构建自己的原语。

通常使用recipes表示原语的实现。包括ZooKeeper操作和维护一个小型的数据节点，这些节点称为znode，采用类似于文件系统的层级树结构进行管理。

针对一个znode，没有数据常常表达了重要的信息。

#### API概述

znode节点可能含有数据，也可能没有。如果一个znode节点包含任何数据，那么数据存储为字节数组。ZooKeeper并不直接提供解析的支持。

ZooKeeper的API暴露了一下方法：

`create /path data`

​	创建一个名为`/path`的znode节点，并包含数据`data`

`delete /path`

​	删除名为`/path`的znode

`exists /path`

​	检查是否存在名为`/path`的节点，在3.6中没有该命令，可以用`stat /path`查看znode的信息

`setData /path data`

​	设置名为`/path`的znode的数据为data，在3.6中好像是`set /path “data”`

`getData /path`

​	返回名为`/path`节点的数据信息

`getChildren /path`

​	返回`/path`节点的所有子节点列表，在3.6中为`get /path`

ZooKeeper不允许局部写入或读取znode节点的数据。

ZooKeeper客户端连接到ZooKeeper服务，通过API调用来建立会话`session`。

#### znode的不同类型

**持久节点和临时节点**

持久的znode只能通过调用`delete`来进行删除。

临时的znode节点在一下两种情况下会被删除：

-   当创建该节点的客户端的会话因超时或主动关闭而中止时
-   当某个客户端（不一定是创建者）主动删除该节点

当前不允许临时节点有子节点，但是以后可能会允许。

**有序节点**

一个有序节点被分配唯一一个单调递增的整数。当创建有序节点时，一个序号会被追加到路径之后。

因此znode分为：持久的，临时的，持久有序的和临时有序的。

#### 监视与通知

ZooKeeper采用基于通知`notification`的机制：客户端向ZooKeeper注册需要接收通知的znode，通过对znode设置监视点`watch`来接收通知。监视点是一个单次触发的操作，意即监视点会触发一个通知。为了接收多个通知，客户端必须在每次通知后设置一个新的监视点。

因为通知机制是单次触发的操作，所以在客户端接收一个znode变更操作并设置新的监视点时，znode节点也许发生了新的变化。但不会错过状态的变化。

**通知机制的重要保障：**对同一个znode的操作，先向客户端传送通知，然后再对该节点进行变更。

通知机制是一种异步回调的触发机制。具有如下特性：

-   一次触发
-   发往客户端：watches异步发往客户端，ZooKeeper提供一个顺序保证：在看到watch事件之前绝不会看到变化，这样不同的客户端看到的是一致性的顺序。ZooKeeper会保证次序：在收到观察事件之前，客户端不会看到已经为之设置观察的节点的变动。网络延迟或者其他因素可能会让不同的客户端在不同的时间收到观察时间和更新操作的返回码，但可以确保不同的客户端看到的事情都有一致的次序。
-   为数据设置watch：节点有不同的改动方式，ZooKeeper维护两个观察列表：数据观察和子节点观察。`getData`和`exists`设置数据观察，`getChildren`设置子节点观察。不同的返回数据有不同的观察。
-   时序性和一致性：watcher是在client连接到ZooKeeper服务端的本地维护。当一个client连接到新server，watch将会触发任何session事件，断开连接后不能接收到。当客户端重连，先前注册的watcher将会被重新注册并触发。

#### 版本

每一个znode都有一个版本号，随着每次数据变化而自增。可以使用`stat /path`中的查看具体信息，如果是znode数据变化，则查看`dataVersion`。如果是子节点变化，可以查看`cversion`。

当多个ZooKeeper客户端对同一个znode操作时，版本的使用非常重要。在写入数据时会比较版本号，如果版本号无法匹配，就会使得操作失败。

### ZooKeeper架构

ZooKeeper服务器端运行于两种模式：独立模式`standalone`和仲裁模式`quorum`。

独立模式：一个单独的服务器，ZooKeeper状态无法复制。

仲裁模式：一组ZooKeeper服务器，称为ZooKeeper集合`ZooKeeper ensemble`，可以进行状态的复制，并同时服务客户端的请求。

#### ZooKeeper仲裁

在ZooKeeper中，仲裁也是依据法定人数的方法来确认保证服务器有效运行的服务器最小个数。

#### 会话

在对ZooKeeper集合执行任何请求前，客户端必须先与服务建立会话。客户端提交给ZooKeeper的所有操作均关联在一个会话上。当一个会话因某种原因而中止时，在这个会话期间创建的临时节点将会消失。

如果会话无法与当前连接的服务器继续通信时，会话可能转移到另一个服务器上。ZooKeeper客户端库透明地转移一个会话到不同的服务器。

会话提供顺序保证，但同一个客户端有多个会话时不能保证顺序性。

### 开始使用ZooKeeper

#### 会话的状态和声明周期

会话的生命周期指会话从创建到结束的时期。

主要的可能状态有：CONNECTING、CONNECTED、CLOSED和NOT_CONNECTED。

如果客户端与服务器因超时而断开连接，客户端仍然保持CONNECTING状态。如果因网络分区问题导致客户端与ZooKeeper集合被隔离而发生连接断开，状态一直保持，直到显式地关闭这个会话，或者分区问题修复后，客户端能够获悉ZooKeeper服务器发送的会话已经过期。**客户端只能等待服务端发送会话过期，自己不能声明自己的会话过期。**

创建会话时，设置会话超时参数。经过时间t之后，服务接收不到会话的任何消息，服务就会声明会话过期。客户端在经过$t/3$时间后未收到任何消息，客户端将向服务端发送心跳信息。在经过$2t/3$时间后，客户端开始寻找其他服务器，此时有$t/3$的时间去寻找。

在仲裁模式下，应用需要传递可用的服务器列表给客户端，告知客户端可以连接的服务器信息并选择一个进行连接。

如果连接到一个不同的服务器时，**这个服务器的ZooKeeper状态需要与最后连接的服务器的ZooKeeper状态保持最新**。即客户端不能连接到比它更老的服务器。ZooKeeper通过在服务中排序更新操作来决定状态是否最新。ZooKeeper确保每一个变化相对于所有其他已执行的更新是完全有序的。在ZooKeeper实现中，系统会根据每一个更新建立的顺序来分配给事务标识符`zkid`。

#### ZooKeeper与仲裁模式

启动ZooKeeper集群时，需要在`zoo.cfg`配置文件中加入语句：

~~~sh
server.1=127.0.0.1:2222:2223
server.2=127.0.0.1:3333:3334
server.3=127.0.0.1:4444:4445
~~~

每一个server.n项指定了编号为n的ZooKeeper服务器使用的地址和端口号。每个server.n项通过冒号分隔为三个部分，第一部分为服务器n的IP地址或主机名，第二部分和第三部分为TCP端口号，分别用于仲裁通信和群首选举。

#### 实现一个原语：通过ZooKeeper实现锁

使用ZooKeeper的接口来管理一个znode，以此来实现锁。为了获得一个锁，每个进程p尝试创建znode，名为`/lock`。如果进程p成功创建了znode，就表示它获得了锁并可以继续执行其临界区域的代码。但要注意如果进程崩溃或者网络故障，导致锁无法释放的问题。

因此需要指定`/lock`为临时节点。。

其他进程因znode存在而创建`/lock`失败。因此，进程监听`/lock`的变化，并在检测到`/lock`删除时再次尝试创建节点来获得锁。当收到`/lock`删除的通知时，如果进程p’还需要继续获取锁，它就继续尝试创建`/lock`的步骤，如果其他进程已经创建了，就继续监听节点。

### 一个主-从例子的实现

一般主-从模式的模型包括三个角色：

-   主节点：负责监听新的从节点和任务，分配任务给可用的从节点
-   从节点：从节点通过系统注册自己，以确保主节点看到它们可以执行任务，然后开始监视新任务
-   客户端：创建新任务并等待系统的响应

#### 主节点角色

如果是单ZooKeeper服务器，可以通过创建临时节点当做主节点

~~~sh
create -e /master "主机信息"
~~~

其中`create`的`-e`选项表示创建临时节点

当节点已经创建，再次创建就是失败。考虑到一个活动的主节点可能会崩溃，备份主节点需要接替活动主节点的角色，需要在`/master`节点上设置一个监视点。

~~~sh
stat -w /master//3.6.2版本改为-w选项
~~~

其中`-w`选项表示为`/master`节点放置一个监视点。

当节点的值发生变化时，会进行通知。

~~~sh
WatchedEvent state:SyncConnected type:NodeDataChanged path:/master
~~~

如果备份主节点监视到主节点被删除，需要创建新的主节点

#### 从节点、任务和分配

由于需要监视子节点变化，可以由下列语句实现：

~~~sh
ls -w /works
~~~

这个语句可以监视`/works`目录下所有子节点变化情况

#### 从节点角色

从节点首先在`/works`子节点下创建临时性的znode来通知主节点，并在子节点中使用主机名来标识自己：

~~~sh
create -e /workers/worker1.example.com "worker1.example.com:2224"
~~~

一旦节点创建成功，主节点通过监视器得知节点变化。然后从节点需要创建一个父节点`/assign/worker1.example.com `来接收任务分配，并通过第二个参数为`-w`的`ls`命令来监视这个节点的变化，以便等待新的任务。

~~~sh
//从节点
create -e /workers/worker1.example.com "worker1.example.com:2224"
create /assign/worker1.example.com ""
ls -w /assign/worker1.example.com
~~~

此时，从节点准备就绪，可以接收任务分配。

#### 客户端角色

客户端向系统中添加任务。

~~~sh
create -s /tasks/task- "cmd"
~~~

其中`create`语句的`-s`选项表示顺序。本质为一个队列。

接下来可以利用监视机制，来获得任务的完成情况。

比如可以建立一个`/tasks/task-00000`，然后客户端监视这个节点的子节点变化情况。

当客户端建立该节点后，主节点会收到监视通知，然后获取可用的从节点列表，然后分配这个任务给一个从节点：

~~~sh
create /assign/worker1.example.com/task-00000 ""
~~~

从节点根据监视通知，得知有一个新的任务，然后确认任务列表，然后执行任务。一旦执行完毕，就在`/tasks`中添加一个状态znode：

~~~sh
create /tasks/task-00000/status "done"
~~~

客户端接收到通知，并检查执行结果。检查状态znode的信息，并确认任务的执行结果。

## 使用ZooKeeper进行开发

使用go-zookeeper库进行学习。

文档：https://godoc.org/github.com/samuel/go-zookeeper/zk#pkg-index

GitHub：https://github.com/go-zookeeper/zk

### 建立ZooKeeper会话

~~~go
func Connect(servers []string, sessionTimeout time.Duration, options ...connOption) (*Conn, <-chan Event, error) 
~~~

建立一个新的会话。其中第一个参数为ZooKeeper服务器地址，如果有多个，可依次填写，格式为`IP:PORT`，其中PORT=2181时可省略。第二个参数为会话超时。其中第三个参数为连接选项，是一个函数：

~~~go
type connOption func(c *Conn) 
~~~

支持的函数接口有：

~~~go
func WithDialer(dialer Dialer) connOption
func WithHostProvider(hostProvider HostProvider) connOption
func WithLogger(logger Logger) connOption
func WithLogInfo(logInfo bool) connOption
func WithEventCallback(cb EventCallback)
~~~

如果填写多个ZooKeeper服务器地址，假如当前连接z1，同时注册一个监听子节点的监视器。现在删除杀死z1，此时客户端会自动连接其他服务器。

其中返回值`Conn`代表会话连接。`Event`代表监视器，默认缓冲区为6。

**ZooKeeper管理连接**：ZooKeeper客户端库会监控与服务之间的连接，客户端库会告诉连接之间发生的问题，还会主动尝试重新建立通信。

测试：

~~~go
package main
                               
import (
    "fmt"
    "time"

    "github.com/go-zookeeper/zk"
)

func main() {
    conn, connwatch, err := zk.Connect([]string{"127.0.0.1:2181"}, time.Second)
    if err != nil {
        panic(err)
    }
    defer conn.Close()
    go func() {
        for {
            event := <-connwatch
            fmt.Println("conn watch:", event)
        }
    }()
    for {
    }
}
~~~

如果ZooKeeper服务器在运行，正常输出：

~~~sh
conn watch: {EventSession StateHasSession  <nil> 127.0.0.1:2181}
~~~

如果突然杀死ZooKeeper服务器，输出如下：

~~~sh
conn watch: {EventSession StateConnecting  <nil> 127.0.0.1:2181}
2020/10/05 21:00:21 failed to connect to 127.0.0.1:2181: dial tcp 127.0.0.1:2181: connect: connection refused
~~~

然后再重启ZooKeeper服务器，会重新建立连接。

### 获取管理权

ZooKeeper通过插件式的认证方法提供了每个节点的ACL策略功能，因此，可以限制某个用户对某个znode节点的权限。

例程：

~~~go
package main
                               
import (
    "fmt"
    "os"
    "strconv"
    "time"

    "github.com/go-zookeeper/zk"
)

func main() {
    conn, event, err := zk.Connect([]string{"127.0.0.1:2181"}, time.Second)
    if err != nil {
        panic(err)
    }
    defer conn.Close()
    go func() {
        for cur := range event {
            fmt.Println("conn event:", cur) 
        }
    }()
    children, stat, childevent, err := conn.ChildrenW("/")
    if err != nil {
        panic(err)
    }
    fmt.Println("children:", children, "stat:", *stat, "err:", err)
    childwatch := <-childevent
    fmt.Println("childwatch:", childwatch)
    pid := strconv.Itoa(os.Getpid())
    fmt.Println("cur pid:", pid)
    res, err := conn.Create("/newmaster", []byte(pid), zk.FlagTTL, zk.WorldACL(zk.PermAll))
    if err != nil {
        fmt.Println("create fail:", err)
    }
    fmt.Println("Create res:", res) 
}
~~~

运行ZooKeeper服务器后，连续运行上面的程序三次。然后改变ZooKeeper服务器下根目录的子节点数量，这样三个客户端就会争抢创建`/newmaster`子节点。在调用时需要注意ACL权限。

当一个任务加入队列，主节点需要唤醒并分配任务给一个从节点，从节点需要找出分配给自己的任务，任务完成时，客户端需要及时知道，如果主节点故障，另一个等待中的主节点需要接管主节点工作。如果从节点故障，分配给这个从节点的任务需要分配给其他从节点。

## 处理状态变化

通过监视点，客户端可以对指定的znode节点注册一个通知请求，在发生变化时就会收到一个单次的通知。

### 单次触发器

**事件(Event)**：表示一个znode节点执行了更新操作。

一个**监视点(watch)**表示一个与之关联的znode节点和事件类型组成的单次触发器。当一个监视点被一个事件触发时，就会产生一个通知。通知是注册了监视点的应用客户端收到的事件报告的信息。

当应用程序注册了一个监视点来接收通知，匹配该监视点条件的第一个事件会触发监视点的通知，并且最多触发一次。

客户端设置的监视点与会话关联，如果会话过期，等待中的监视点将会被删除。但是监视点可以跨越不同服务端的连接而保持。当一个ZooKeeper客户端与ZooKeeper服务端的连接断开后连接到集合中的另一个服务器，客户端会发送未触发的监视点列表，在注册监视点时，服务端将要检查已监视的znode节点在之前注册监视点之后是否已经变化，如果znode节点已经发生变化，一个监视点的事件就会被发送给客户端，否则在新的服务端上注册监视点。

**单次触发是否会丢失事件**：一个应用在接收到通知后，，注册另一个监视点时，可能会丢失事件，但是比如通过`getChildren`获取子节点列表时注册监视点，从而保证客户端不会丢失任务。

监视点一旦设置无法移除。要想移除一个监视点，一是触发这个监视点，二是使其会话被关闭或过期。

监视点的操作执行成功后就会为一个znode节点设置一个监视点，如果ZooKeeper的操作因为客户端连接断开而失败，应用需要再次执行这些调用。

### multiop

`multiop`可以原子性地执行多个ZooKeeper的操作，执行过程为原子性，即在`multiop`代码块中的所有操作要不全部成功，要不全部失败。

### 通过监视点代替显式缓存管理

一个高效的方式是客户端本地缓存ZooKeeper的znode节点数据，在需要时使用这些数据，一旦数据发生变化，可以让ZooKeeper通知客户端，客户端更新缓存的数据，监视点可以让客户端在本地缓存一个版本的数据，并在数据发生变化时接收到通知来进行更新。

### 顺序的保障

#### 写操作的顺序

服务端对状态的变化的顺序达成一致，并使用相同的顺序执行状态的更新。不同服务端之间可能在不同时间执行状态变化，因为以不同的速度运行。

#### 读操作的顺序

**隐藏通道**：

-   客户端c1更新了`/z`节点的数据，并收到应答
-   客户端c1通过TCP的直接连接告诉客户端c2，`/z`节点状态发生了变化
-   客户端c2读取`/z`节点的状态，但是在c1更新之前就观察到这个状态

这被称为隐藏通道，因为ZooKeeper并不知道客户端之间额外的通信。应用程序使用ZooKeeper进行所有涉及ZooKeeper状态的通信。

#### 通知的顺序

ZooKeeper对通知的排序涉及其他通知和异步响应，以及对系统状态更新的顺序。

比如：假如有一个znode`/config`，其子节点包含应用配置元数据：`/cpnfig/m1,/config/m2`等等。假如主节点应用进程通过`setData`更新每个znode节点，且不能让客户端只读取到部分更新，一个解决办法是在开始更新这些配置前，主节点先创建一个`/config/invalid`节点，其他需要读取这一状态的客户端会监视`/config/invalid`节点，如果该节点存在就不会读取配置状态，当该节点被删除，就意味着有一个新的有效的配置节点集合可用，客户端可以读取该集合的操作。

另一种方法是使用`multiop`来对`/config/m[1-n]`这些节点原子地执行所有`setData`操作，而不是使用一个znode节点来标识部分修改的状态。

ZooKeeper根据触发通知的状态更新对通知消息进行排序，客户端可以通过这些通知感知到真正的状态变化的顺序。

**活性和安全性**：活性`liveness`会确保系统最终取得进展。新任务和新的从节点的通知只是关于活性的事件的例子。原子更新一组配置节点的例子，主要涉及安全性。对于活性的例子中，通知的传送顺序不是特别重要，只要客户端最终获知这些事件就可以继续，但是为了安全性，不按顺序接收通知，可能会导致不正确的行为。

### 监视点的羊群效应和可扩展性

当发生变化时，ZooKeeper会触发一个特定的znode节点的变化导致的所有监视点的集合。如果有1000个客户端通过`exists`操作监视这个znode节点，当znode节点创建后会发送1000个通知，因而被监视的znode节点的一个变化为产生一个尖峰的通知，该尖峰可能带来影响。比如操作延迟。建议在使用ZooKeeper时，避免在一个特定节点设置大量的监视点，最好每次在特定的znode节点上，只有少量的客户端设置监视点，理想情况下最多只设置一个。

比如抢锁：

-   所有进程都尝试创建`/lock`节点，未抢到锁的监视`/lock`节点的删除事件。
-   所有进程创建一个`/lock/lock-xxx`的有序节点，客户端通过`/getChildren`方法获取所有`/lock`下的子节点，如果自身是最小的序号，代表抢到锁，否则就监视前一个节点。比如有`/lock/lock-1`、`/lock/lock-2`和`/lock-lock-3`。其中`/lock-1`抢到锁，`/lock-2`监视`/lock-1`，`/lock-3`监视`/lock-2`。这样每个节点上设置的监视点只有最多一个客户端。

设置一个监视点可能会使服务端的监视点管理器的内存消耗增加250-300字节，因此需要注意设置的监视点数量。

## 故障处理

### 可恢复的故障

ZooKeeper呈现给使用某些状态的所有客户端进程一致性的状态视图。当一个客户端从ZooKeeper获得响应时，客户端可以非常肯定这个响应信息与其他响应信息或其他客户端所接收的响应均保持一致性。

如果客户端与服务器失联，客户端库会积极尝试重新连接另一个ZooKeeper服务器，直到最终重新建立一个会话。一旦会话重新建立，ZooKeeper会产生一个`SyncConnected`事件，并开始处理请求。ZooKeeper还会注册之前已经注册过的监视点，并对失去连接的这段时间发生的变更产生监视点事件。

**当一个进程失去连接后就无法收到ZooKeeper的更新通知。**因此，一个进程可能会在会话丢失时错过某些重要的状态变化。

当整个ZooKeeper集合停机时，时间冻结。当整个集合恢复后，会话的超时时间被重置，客户端回到之前的正确状态，进程不用额外地重启延长时间。

**已存在的监视点与Disconnected事件**

为了使连接断开与重现建立会话之间更加平滑，ZooKeeper客户端会在新的服务器上重新建立所有已存在的监视点。当客户端连接ZooKeeper服务器，客户端会发送监视点列表和最后已知的zxid(最终状态的时间戳)，服务器会接受这些监视点并检查znode节点的修改时间戳与这些监视点是否对应，如果任何已经监视的znode节点的修改时间戳晚于最后已知的zxid，服务器就会触发这个监视点。

每个ZooKeeper操作都完全符合逻辑，除了`exists`。因为`exists`操作与其他操作不同，因为这个操作可以在一个不存在的节点上设置监视点。举例：

如果客户端c1往服务器监视`/events`节点是否存在，此时不存在，然后断开连接操作，客户端c2往服务器创建`/events`节点，然后又删除该节点，客户端c1又重新连接，此时`/events`节点还是不存在，无法触发事件。针对这种情况，应尽量监视存活期更长的znode节点。

**自动重连处理危害**

有些ZooKeeper的封装库通过简单的补发命令自动处理连接丢失的故障，有些情况下可以接受，但有些情况下可能会导致错误的结果。比如`/leader`节点用来建立领导权，程序在执行`create`操作建立`/leader`节点时连接丢失，而盲目地重试`create`操作会导致第二个`create`操作执行失败，因为`/leader`节点已经存在，因此该进程就会假设其他进程获得了领导权。此时应该可以识别并处理这种情况。

### 不可恢复的故障

有时会话会无法恢复而必须被关闭。常见的原因是会话过期，另一个原因是已认证的会话无法再次与ZooKeeper完成认证。这两种情况下，ZooKeeper会丢弃会话的状态。

这种情况下最明显的例子是临时节点，这种节点在会话关闭时会被删除。会话关闭时，ZooKeeper内部也会丢弃一些不可见的状态。

当客户端无法提供适当的认证信息来完成会话的认证时，或Disconnected事件后客户端重新连接到已过期的会话，就会发生不可恢复的故障。

处理不可恢复故障的最简单的方法是中止进程并重启，这样可以使进程恢复原状，通过一个新的会话重新初始化自己的状态。如果该进程继续工作，首先必须要清除与旧会话关联的应用内部的进程状态信息，然后重新初始化新的状态。

**从不可恢复故障自动恢复的危害**

简单地重新创建ZooKeeper句柄以覆盖旧的句柄，这会引发一些问题。比如一个认为自己是群首的一个进程的会话中断，但是在通知该进程的其他管理线程它自己不是群首之前，这些线程通过新句柄操作哪些只应该被群首访问的数据。此时如果修改ZooKeeper中的数据，就会引起不可预测的危害。

### 群首选举和外部资源

当运行客户端进程的主机发生过载，就会开始发生交换、系统震荡或因发生超负荷的主机资源的竞争而导致的进程延迟，这些会影响与ZooKeeper交互的及时性。一方面，ZooKeeper无法及时地与ZooKeeper服务器发送心跳信息，导致ZooKeeper的会话超时，另一方面，主机上本地线程的调度会导致不可预知的调度：一个应用线程认为会话仍然处于活动状态，并持有主节点，即使ZooKeeper线程有机会运行时才会通知会话已经超时。

另一方面可能由于时钟偏移。有时候时钟偏移会导致时间变慢甚至落后，使得客户端认为自己还安全地处于超时周期之内，因此仍然具有管理权，尽管其会话已经被ZooKeeper置为过期。

解决方法：

-   确保应用不会在超载或时钟偏移的环境中运行，小心监控系统负载可以检测到环境可能出现问题的可能性，良好设计的多线程应用也可以避免超载，时钟同步程序可以保证系统时钟的同步。
-   通过ZooKeeper扩展对外部设备协作的数据，使用一种名为隔离`fencing`的技巧，分布式系统中常常使用这种方法用于确保资源的独占访问。

比如：在创建群首节点时，可以获得`Stat`结构的信息，其中该结构中的成员之一`czxid`表示创建该节点时的`zxid`，`zxid`为唯一的单调递增的序列号，因此可以用`czxid`作为一个隔离的符号。

当对外部资源进程请求时，或在连接外部资源时，需要提供这个隔离符号。如果外部资源已经接收到更高版本的隔离符号的请求或连接时，我们的请求或连接就会被拒绝。即使出现系统超载或时钟偏移，隔离技巧依然可以可靠地工作。

隔离方案需要修改客户端与资源之间的协议，需要在协议中添加`zxid`，外部资源也需持久化保存来跟踪接收到的最新的`zxid`。

更实际的做法是使用资源锁来确定领导权，为了提供有用信息的目的，由群首创建`/leader`节点。

## ZooKeeper的注意事项

### 使用ACL

每次创建znode节点时，必须设置访问权限，而且子节点并不会继承父节点的访问权限。访问权限的检查也是基于每一个znode节点，如果一个客户端可以访问一个znode节点，即使这个客户端无权访问该节点的父节点，仍然可以访问这个znode节点。

ZooKeeper通过访问控制表`ACL`来控制访问权限。一个`ACL`包括以下形式的记录：`scheme:auth-info`，其中`scheme`对应了一组内置的鉴权模式，`auth-info`为对于特定模式所对应的方式进行编码的鉴权信息。ZooKeeper通过检查客户端进程访问每一个节点时提交上来的授权信息来保证安全性。如果一个进程没有提供鉴权信息，或者鉴权信息与要请求的znode节点的信息不匹配，进程就会收到一个权限错误。

一个进程可以在任何时候调用`AddAuth()`来添加鉴权信息。

#### 内置的鉴权模式

ZooKeeper提供了多种内置模式进行ACL的处理。一种是`world`鉴权模式，使用`anyone`作为`auth-info`，对于`world`这种鉴权模式，只能使用`anyone`这种`auth-info`。

另一种特殊的内置模式为管理员所使用的super模式，该模式不会被列入到任何ACL中，但可以用于ZooKeeper的鉴权。一个客户端通过super鉴权模式连接到ZooKeeper后，不会被任何节点的ACL所限制。

`digest`内置鉴权模式，该模式的`auth-info`格式为`userid:passwd_digest`，当调用`digest`鉴权模式时，需要设置ACL的`userid:password`信息。其中`passwd_digest`为用户密码的加密摘要。如果需要向ZooKeeper提供鉴权信息时，需要使用`digest userid:password`。例如，当使用zkCli.sh连接到ZooKeeper，可以使用下列语句：

~~~sh
[zk: localhost:2181(CONNECTED) 14] addauth digest YY:123
~~~

如果一条连接对于一个znode节点具有`ADMIN`权限，当其他管理员删除这条ACL记录时，也可以随时访问任何znode节点。

如果一个用户被限制访问某个节点，但是其子节点的ACL权限开放，此时该用户可以访问子节点。

**用户名和摘要信息**

用户名和摘要信息不用对应任何真实系统的标识，甚至用户名可以重复。但是相同用户名的密码一样时会发生冲突，因为这样会导致可以互相访问对方的信息。

`ip鉴权模式`：`10.11.12.0/24`提供网络地址和掩码，因为需要调用客户端的地址来进行ACL策略的检查，客户端在使用ip模式的ACL策略访问znode节点时，不需要调用`AddAuth`函数。该鉴权模式假设IP地址无法被伪造，但是这个假设不能使用任何模式。

#### SASL和Kerberos

如果新的开发人员加入或离开组，管理员需要改变所有ACL策略。其次，如果需要修改某些开发人员的密码，也需要修改所有的ACL策略。最后，如果网络不可信，无论是`digest`模式还是`ip`模式都不是最合适的模式。可以通过`sasl`模式来解决这些问题。

SASL表示简单认证与安全层。SASL将底层系统的鉴权模型抽象为一个框架，因此可以使用SASL框架，并使用SASL支持多种协议。在ZooKeeper中，SASL常常使用`Kerberos`协议，该鉴权协议提到的各种缺失的功能。在使用SASL模式时，使用sasl作为模式名，id则使用客户端的Kerberos的ID。

SASL是ZooKeeper的扩展鉴权模式，因此需要通过配置参数激活该模式。

#### 增加新鉴权模式

ZooKeeper还可以使用其他的任何鉴权模式。对于新的鉴权模式来说只是简单的编码问题。

### 恢复会话

当客户端崩溃后恢复，此时客户端不要使用任何之前从ZooKeeper获取的缓存状态，而是使用ZooKeeper作为协作状态的可信来源。

另外，客户端崩溃时，已经提交给ZooKeeper的待处理操作也许已经完成，由于客户端崩溃导致无法收到确认消息，ZooKeeper无法保证这些操作肯定会成功执行，因此客户端在恢复时也许需要进行一些ZooKeeper状态的清理操作，以便完成某些未完成的任务。

对于会话过期，不能认为是客户端崩溃。会话也许因为网络问题或其他问题过期。在会话过期的情况下，客户端需要考虑ZooKeeper状态也许已经发生了变化，或者客户端对ZooKeeper的请求也许并未完成。

### 当znode节点重新创建时，重置版本号

znode节点被删除并重建时，其版本号会被重置。

### sync方法

主要解决隐蔽通道的问题。调用`sync`方法后，服务端保证返回所有客户端c调用sync方法时的所有可能的变化情况。

### 顺序性保障

#### 连接丢失时的顺序性

对于连接丢失事件，ZooKeeper会取消等待中的请求，对于同步方法的调用客户端库会抛出异常，对于异步请求调用，客户端调用的回调函数会返回结果码来标识连接丢失。在应用程序的连接丢失后，客户端库不会再次重新提交请求，因此就需要应用程序对已经取消的请求进行重新提交的操作。在连接丢失的情况下，应用程序可以依赖客户端库来解决所有后续操作，而不能依赖ZooKeeper来承担这些操作。

#### 同步API和多线程的顺序性

如果多个线程同时提交同步操作，可能由于线程调度，导致后提交的先执行，此时需要注意提交的顺序性。

#### 同步和异步混合调用的顺序性

异步提交两个请求：`Aop1`和`Aop2`。在`Aop1`的回调函数中，执行了一个同步调用`Sop1`，该同步阻塞了ZooKeeper客户端的分发线程，这样就会导致客户端应用程序接受`Sop1`的结果之后才能接收到`Aop2`的操作结果。因此应用程序观察到的操作结果顺序为`Aop1`、`Sop1`、`Aop2`，而实际的提交顺序并非如此。

### 数据字段和子节点的限制

ZooKeeper默认情况下对数据字段的传输限制为`1MB`，该限制为任何节点数据字段的最大可存储字节数，同时也限制了任何父节点可以拥有的子节点数。如果一个znode节点可以存储很大的数据，就会在处理时消耗更多的时间，甚至在处理请求时导致处理管道的停滞。

## ZooKeeper内部原理

群首作为中心点处理所有对ZooKeeper系统变更的请求，就像一个定序器，建立所有对ZooKeeper状态更新的顺序，追随者接收群首所发出更新操作请求，并对这些请求进行处理，以此来保障状态更新操作不会发生碰撞。

群首和追随者组成了保障状态变化有序的核心实体，同时还存在第三类服务器，称为观察者。观察者不会参与决策哪些请求可被接受的过程，只是观察决策的结果，观察者的设计只是为了系统的可扩展性。

### 请求、事务和标识符

ZooKeeper服务器会在本地处理只读请求`exists、getData、getChildren`。假如一个服务器接收到客户端的`getData`请求，服务器读取该状态信息，并将这些信息返回给客户端。因为服务器会在本地处理请求，所以ZooKeeper在处理以只读请求为主要负载时，性能会很高。可以增加更多的服务器到ZooKeeper集群中，这样就可以处理更多的读请求，大幅提高整体处理能力。

会改变ZooKeeper状态的客户端请求`create、delete、setData`将会被转发给群首，群首执行相应的请求，并形成状态的更新，称为**事务**`transaction`。其中，请求源自于客户端发起的操作，事务则包含了对应请求处理而改变ZooKeeper状态所需要执行的步骤。

举例：假如一个客户端提交了一个对`/z`节点的`setData`请求，`setData`将会改变znode节点数据信息，并会增加该节点的版本号，因此对于这个请求的事务包含了两个重要字段：节点中新的数据字段值和该节点新的版本号。当处理该事务时，服务端将会用事务中的数据信息来替换`/z`节点中原来的数据信息，并会用事务中的版本号更新该节点，而不是增加版本号。

一个事务为一个单位，即所有的变更处理需要以原子方式之心。以`setData`的操作为例，变更节点的数据信息，但并不改变版本号将会导致错误的发生，因此，ZooKeeper集群以事务方式运行，并确保所有的变更操作以原子方式被执行，同时不会被其他事务所干扰。

一个事务具有幂等性，对一个事务或者多个事务，只要执行顺序一致，执行多次的结果是一致的。

当群首产生一个事务，就会为该事务分配一个标识符，称为ZooKeeper会话的ID`zxid`，通过`Zxid`对事务进行标识，就可以按照群首所指定的顺序在各个服务器中按序执行服务器之间在进行新的群首选举时也会交换`zxid`信息，这样就可以知道哪个无故障服务器接收了更多的事务，并可以同步他们之间的数据。

`zxid`为一个long型整数，分为时间戳部分和计数器。每个部分32位。

### 群首选举

群首为集群中的服务器选择出来的一个服务器，并会一直被集群所认可。设置群首的目的是为了对客户端所发起的ZooKeeper状态变更请求进行排序，包括`create、setData和delete`操作。群首将每一个请求转换为一个事务，将这些事务发送给追随者，确保集群按照群首确定的顺序接受并处理这些事务。

选举并支持一个群首的集群服务器数量必须至少存在一个服务器进程的交叉，使用属于仲裁`quorum`来表示这样一个进程的子集，仲裁模式要求服务器之间两两相交。

一组服务器达到仲裁数量是必需条件，如果足够多的服务器永久性地退出，无法达到仲裁法定数量，ZooKeeper也就永远无法取得进展。即使服务器退出后再次启动也可以，但必须保证仲裁的法定数量的服务器最终运行起来。重新配置可以随时间而改变仲裁法定数量。

每个服务器启动后进入`LOOKING`状态，开始选举一个新的群首或查找已经存在的群首，如果群首已经存在，其他服务器就会通知这个新启动的服务器，告知哪个服务器是群首，与此同时新的服务器与群首建立连接，以确保自己的状态与群首一致。

如果集群中的所有服务器均处于`LOOKING`状态，这些服务器之间就会进行通信来选举一个群首，通过信息交换对群首选举达成共识的选择。在本次选举过程中胜出的服务器进入`LEADING`状态，而集群中其他服务器进入`FOLLOWING`状态。

对于群首选举的消息，称为群首选举通知消息。协议：当一个服务期进入`LOOKING`状态，就会向集群中每个服务器发送一个通知消息，该消息中包括该服务器的投票消息，投票中包含服务器标识符`sid`和最近执行的事务的`zxid`信息，比如，一个服务器所发送的投票信息为(1,5)，表示该服务器的`sid`为1，最近执行的事务的`zxid`为5（出于群首选举的目的，`zxid`只有一个数字，而在其他协议中，`zxid`则有时间戳和计数器组成）。

当一个服务器收到一个投票信息，该服务器会根据以下规则修改自己的投票信息：

1.  将接收到的`voteId`和`voteZxid`作为一个标识符，并获取接收方当前的投票中的`zxid`，用`myZxid`和`mySid`表示接收方服务器自己的值
2.  如果`voteZxid>myZxid`或者`voteZxid=myZxid且voteId>mySid`，保留当前的投票信息
3.  否则，修改自己的投票信息，将`voteZxid`赋值给`myZxid`，将`voteId`赋值给`mySid`.

简而言之，只有最新的服务器将赢得选举，因为其拥有最近一次的`zxid`。这样做将会简化群首崩溃后重新仲裁的流程。如果多个服务器拥有最新的`zxid`值，其中的`sid`值最大的将赢得选举。

当一个服务器接收到仲裁数量的服务器发来的投票都一样时，就表示群首选举成功，如果被选举的群首为某个服务器自己，该服务器将会开始行使群首角色，否则就成为一个追随者并尝试连接被选举的群首服务器。但是，不能保证追随者必然会成功连接上被选举的群首服务器，比如，被选举的群首此时崩溃。一旦连接成功，追随者和群首之间将会进行状态同步，在同步完成后，追随者才可以处理新的请求。

加入一个服务器由于网络延迟等影响，没有投票给`zxid`较大的服务器，会进行等待，其他服务器投票给具有最大`zxid`的服务器，达到法定人数后，具有最大`zxid`的服务器将会成为群首，而投票错误的服务器会等待它投票的服务器的响应消息。这个等待时间一般比消息延迟大，但与恢复时间相比不够长。有时会导致一个或多个服务器错误选举群首，从而导致群首没有足够的追随者，服务器将会再次进行群首选举。错误选举一个群首可能会导致整个恢复时间更长，因为服务器将会进行连接以及不必要的同步操作，并需要发送更多消息来进行另一轮的群首选举。

### Zab：状态更新的广播协议

在接收到一个写请求操作后，追随者会将请求转发给群首，群首将探索性地执行该请求，并将执行结果以事务的方式对状态更新进行广播。一个事务中包含服务器需要执行变更的确切操作，当事务提交时，服务器就会将这些变更反馈到数据树上，其中数据树为ZooKeeper用于保存状态信息的数据结构。

`Zab`：ZooKeeper原子广播协议。假设有一个活动的群首服务器，并拥有仲裁数量的追随者支持该群首的管理权，通过该协议提交一个事务非常简单，类似两阶段提交。

1.  群首向所有追随者发送一个PROPOSAL消息p
2.  当一个追随者接收到信息p后，会响应群首一个ACK消息，通知群首已接受该提案`proposal`
3.  当收到仲裁数量的服务器发送的确认消息后（该仲裁数包括群首自己），群首就会发送消息通知追随者进行提交`COMMIT`操作

在应答提案消息之前，追随者还需要执行一些检查操作。追随者将会检查所发送的提案消息是否属于其所追随的群首，并确认群首所广播的提案消息和提交事务消失的顺序正确。

`Zab`保障以下重要属性：

-   如果群首按顺序广播了事务T和事务T1，那么每个服务器在提交T1事务前保证了事务T已经完成
-   如果某个服务器按照事务T、事务T1的顺序提交事务，所有其他服务器也必然会在提交事务T1前提交事务T

第一个属性保证事务在服务器之间的传送顺序的一致，第二个竖向地保证服务器不会跳过任何事务。假设事务为状态更新操作，每个状态变更操作又依赖前一个状态变更操作的结果，如果跳过事务就会导致结果的不一致性，而两阶段提交保证了事务的顺序。`Zab`在仲裁数量服务器中记录了事务，集群中仲裁数量的服务器需要在群首提交事务前对事务达成一致，而且追随者也会在硬盘中记录事务的确认信息。

事务在某些服务器上可能会终结，而其他服务器上却不会，因为在写入事务到存储中时，服务器也可能发生崩溃。无论何时，只要仲裁条件达成并选举一个新的群首，ZooKeeper都可以将所有服务器的状态更新到最新。

如果活动的群首崩溃或短时间失去连接，需要选举一个新的群首保证系统整体仍然可用。时间戳`epoch`代表了管理权随时间的变化情况，一个时间戳表示某个服务器行使管理权的这段时间，在一个时间戳内，群首会广播提案消息，并根据计数器`counter`识别每一个消息。

时间戳的值在每次新群首选举发生的时候便会增加。同一个服务器称为群首后可能持有不同的时间戳信息，但从协议的角度出发，一个服务器行使管理权时，如果持有不同的时间戳，该服务器被认为是不同的群首。

在仲裁模式下，记录已接收的提案消息非常关键，可以确保所有的服务器最终提交了被某个或多个服务器已经提交完成的事务，即使群首在此时已经发生了故障。完美检测群首（或任何服务器）是否发生故障是非常困难的。

实现这个广播协议所遇到的最多的困难在于群首并发存在的情况。由于时间问题或者消息丢失都可能导致这个情况，因此为了解决这个问题，`Zab`协议提供了以下保障：

-   一个被选举的群首确保在提交完所有之前的时间戳内需要提交的事务，之后才开始广播新的事务
-   在任何时间点，都不会出现两个被仲裁支持的群首

保证第一个需求，群首会等待，确保仲裁数量的服务器认可这个群首新的时间戳。一个时间戳的最初状态必须包含所有的之前已经提交的事务，或者某些已经被其他服务器接受，但尚未提交完成的事务。在群首进行时间戳`e`的任何新的提案前，必须保证自时间戳开始到时间戳`e-1`内的所有提案被提交。如果一个提案消息处于时间戳$e^,<e$，在群首处理时间戳`e`的第一个提案消息前，没有提交之前的这个提案，那么旧的提案永远不会被提交。

对于第二个需求，关键点在于群首$l^,$和$l$在同一时刻并未获得足够的仲裁数量的支持者。在新的群首$l^,$生效前，必须学习旧的仲裁数量服务器之前接受的所有提议，并且保证这些服务器不会继续接受来自旧群首的提议。此时，如果旧群首$l$还能继续