# Kafka权威指南

## 初始Kafka

### 发布与订阅消息系统

发布者以某种方式对消息进行分类，接收者订阅它们，以便接收特定类型的消息。发布与订阅系统一般会有一个broker，即发布消息的中心点。

### Kafka登场

Kafka一般被称为“分布式提交日志”或者“分布式流平台”。文件系统或数据库提交日志用来提供所有事务的持久记录，通过重放这些日志可以重建系统的状态。数据是按照一定顺序持久化保存的，可以按需读取，并且具备数据故障保护和性能伸缩能力。

#### 消息和批次

Kafka的数据单元被称为**消息**。消息可以有一个可选的元数据，即**键**。键是一个字节数组。当消息以一种可控的方式写入不同的分区时，会用到键。最简单的例子是位键生成一个一致性散列值，然后使用散列值对主题分区数进行取模，为消息进行分区。保证具有相同键的消息总是被写入到相同的分区。

为了提高效率，消息被分批次写入Kafka。**批次**是一组消息，这些消息属于同一个主题和分区。

#### 模式

消息模式是一种结构用于定义消息内容。模式和消息体是分开的，当模式发生变化，不需要重新生成代码，支持强类型和模式进化，版本向前兼容，也向后兼容。

#### 主题和分区

Kafka的消息通过**主题**进行分类。主题类似数据库的表。主题可以被分为若干个**分区**，一个分区就是一个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取。一个主题由于含有多个分区，整个主题范围内无法保证消息的顺序，但单个分区内的顺序可以保证。Kafka通过分区来实现数据的冗余和伸缩性。分区可以分布在不同的服务器上，即一个主题可以横跨多个服务器。

通常使用**流**来描述Kafka这类系统的数据。把一个主题的数据看成一个流。流是一组从生产者移动到消费者的数据。

#### 生产者和消费者

Kafka 客户端被分为两种基本的类型：生产者和消费者。

**生产者**创建消息。一般情况下，一个消息会被发布到一个特定的主题上。生产者默认情况下把消息均衡地分布到主题的所有分区上，而不关心特定消息会被写到哪个分区。有时可以通过消息键和分区器来把消息直接写到指定的分区。分区器为键生成一个散列值，并将其映射到指定的分区。从而保证同一个键的消息会被写到同一个分区。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。

**消费者**读取消息。订阅一个或多个主题，并将消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，是一个不断递增的整数值，在创建消息时，Kafka会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的消息偏移量保存在ZooKeeper或Kafka上，如果消费者关闭或重启，读取状态不会丢失。

消费者是**消费者群组**的一部分。会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消息者使用。比如某些消费者会使用多个分区，但不会出现一个分区被多个消费者读取。消费者与分区之间的映射被称为消费者对分区的所有权关系。

通过这种方式，消费者可以消费包含大量消息的主题。并且一个消费者失效，群组里其他消费者可以接管失效消费者的工作。

#### broker和集群

一个独立的Kafka服务器被称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。

broker是集群的组成部分。每个集群都有一个broker同时充当了**集群控制器**的角色（自动从集群的活跃成员中选举出来）。控制器负责管理工作，包括将分区分配给broker和监控broker。在集群中，一个分区从属于一个broker，该broker被称为分区的**首领**。一个分区可以分配给多个broker，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余，如果有一个broker失效，其他broker可以接管领导权。不过相关的消费者和生产者需要重新连接到新的首领。

**保留消息**是Kafka的一个重要特性。默认消息保留策略为：

保留一段时间（比如7天），或者保留到消息达到一定大小的字节数（比如1GB）。当消息数量达到这些上限时，旧消息会过期然后被删除。主题可以配置自己的保留策略，可以将消息保留到不再使用它们为止。可以通过配置把主题当做**紧凑型日志**，只有最后一个带有特定键的消息会被保留下来。

#### 多集群

基于以下原因，最好使用多个集群。

-   数据类型分离
-   安全需求隔离
-   多数据中心（灾难恢复）

如果使用多个数据中心，需要在它们之间复制消息。Kafka的消息复制机制只能在单个集群中进行。

Kafka提供一个MirronMaker工具，可以用于集群间的消息复制。核心组件包括一个生产者和消费者，两者之间通过一个队列相连。

### Kafka的优点

#### 多个生产者

Kafka可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题。适合用来从多个前端系统收集数据，并以统一的格式对外提供数据。

#### 多个消费者

Kafka支持多个消费者从一个单独的消息流上读取数据，而且消费者之间互不影响。另外多个消费者之间可以组成一个群组，共享一个消息流，并保证整个群组对每个给定的消息只处理一次。

#### 基于磁盘的数据存储

Kafka允许消费者非实时地读取消息。消息被提交到磁盘，根据设置的规则进行保存。每个主题可以设置单独的保留规则，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。

#### 伸缩性

broker可以不断扩展，对在线集群进行扩展不影响整体系统的可用性。但要提高集群的容灾能力，需要配置较高的复制系数。

#### 高性能

通过横向扩展生产者、消费者和broker，Kafka可以轻松处理巨大的消息流。在处理大量数据的同时，能保证亚秒级的消息延迟。

## 数据生态系统

Kafka为数据生态系统带来循环接口，在基础设施的各个组件之间传递消息，为所有客户端提供一致的接口。当与提供消息模式的系统集成时，生产者和消费者之间不再有紧密的耦合，也不需要在它们之间建立任何类型的直连。可以根据业务需要添加或移除组件。

## 安装Kafka

### broker配置

#### 常规配置

-   broker.id：每个broker都有一个标识符，使用broker.id来表示。默认值是0，可以被设置为其他的任意整数。在整个Kafka集群里必须是唯一的。

-   port：默认监听9092端口。

-   zookeeper.connect：用于保存broker元数据的ZooKeeper地址。该配置参数是由冒号分隔的一组`hostname:port/path`列表。其中`/path`为可选的ZooKeeper路径，作为Kafka集群的chroot环境。如果不指定，默认为根路径。

-   log.dirs：存放日志片段的目录。是一组用逗号分隔的本地文件系统路径。如果指定多个路径，那么broker会根据“最少使用”原则，把同一个分区的日志片段保存到同一个路径下。broker会往拥有最少数目分区的路径新增分区，而不是拥有最小磁盘空间的路径新增分区。

-   num.recovery.threads.per.data.dir：对于如下3种情况，Kafka会使用可配置的线程池来处理日志片段：

    -   服务器正常启动，用于打开每个分区的日志片段
    -   服务器崩溃后重启，用于检查和截断每个分区的日志片段
    -   服务器正常关闭，用于关闭日志片段

    默认情况下，每个日志片段只使用一个线程。这些线程只是在服务器启动和关闭时会用到，可以设置大量的线程来达到并行操作的目的。设置的数字对应的是log.dirs指定的单个日志目录。假如设置的参数为8，log.dirs指定了3个路径，总共需要24个线程。

-   auto.create.topics.enable：默认情况下，Kafka会在如下几种情况下自动创建主题：

    -   当一个生产者开始往主题写入消息时
    -   当一个消费者开始从主题读取消息时
    -   当任意一个客户端向主题发送元数据请求时

    根据Kafka协议，如果一个主题不先被创建，根本无法知道它是否已经存在，因此可以设置为false。

#### 主题的默认配置

-   num.partitions：指定新创建的主题将包含的分区数。可以增加主题分区的个数，但不能减少。如果要让一个主题的分区个数少于该值，需要手动创建主题。

    选定分区数量：

    -   主题需要达到多大的吞吐量
    -   从单个分区读取数据的最大吞吐量是多少
    -   估算生产者向单个分区写入数据的吞吐量，可以多估算一些
    -   每个broker包含的分区个数、可用的磁盘空间和网络带宽
    -   如果消息按照不同的键来写入分区，为已有的主体新增分区会很困难
    -   单个broker对分区个数有限制，因为分区越多，占用的内存越多，完成首领选举需要的时间越长

-   log.retention.ms：Kafka根据时间来决定数据可以被保留多久。默认使用log.retention.hours参数配置，默认值为168小时，即一周。另外还有log.retention.ms和log.retention.minutes，如果配置多个，取最小值。

    根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现的。

-   log.retention.bytes：另一种方式通过保留的消息字节数来判断消息是否过期。作用在每一个分区上。如果有一个主题含有8个分区，并且该值设置为1G，这个主题最多可以保留8G的数据。当主题的分区个数增加时，整个主题保留的数据随之增加。

    如果同时指定log.retention.ms和log.retention.bytes，只要满足任意一个条件就会删除产品。

-   log.segment.bytes：当日志片段大小达到log.segment.bytes指定的上限（默认是1G），当前日志片段就会被关闭，一个新的日志片段被打开。如果一个日志片段被关闭，就开始等待过期。这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率。

    日志片段的大小会影响使用时间戳获取偏移量。在使用时间戳获取日志偏移量时，Kafka会检查分区里最后修改时间大于指定时间戳的日志片段（已经被关闭的），该日志片段的前一个文件的最后修改时间小于指定时间戳。然后Kafka返回该日志片段开头的偏移量。对于使用时间戳获取偏移量的操作来说，日志片段越小，结果越准确。

-   log.segment.ms：指定多长时间之后日志片段会被关闭。

    在使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性能的影响。如果多个分区的日志片段永远不能达到大小的上限，在broker启动之后就会计算日志片段的过期时间，可能同时关闭多个日志片段。

-   message.max.bytes：限制单个消息的大小，默认值是1000000，即1MB。如果超过限制，消息不会被接收，还会收到broker返回的错误信息。指的是压缩后的大小。对性能有显著的影响。

    消费者客户端设置的fetch.message.max.bytes必须与服务器端设置的消息大小进行协调。如果比message.max.bytes小，那么消费者就无法读取比较大的消息，导致出现消费者被阻塞的情况。为集群broker配置replica.fetch.bytes参数时，也遵循同样的原则。

### 硬件的选择

#### 磁盘吞吐量

生产者客户端的性能直接受到服务器端磁盘吞吐量的影响。

#### 磁盘容量

通过让主题拥有多个分区，集群的总流量可以被均衡到整个集群，如果单个broker无法支撑全部容量，可以让其他broker提供可用的容量。

#### 内存

内存主要影响消费者。消费者一般从分区尾部读取消息，如果有生产者存在，就紧跟在生产者后面。此时，消费者读取的消息会直接存放在系统的页面缓存里。

另外还有网络和CPU。

### Kafka集群

#### 需要多少个broker

首先，需要多少磁盘空间来保留数据，单个broker有多少空间可用。此外，需要考虑集群处理请求的能力。如果单个broker的网络接口在高峰时段可以达到80%的使用量，并且有两个消费者，那么消费者就无法保持峰值，除非有两个broker。如果启用复制功能，要把额外的消费者考虑在内。

#### broker配置

把broker加入到集群，需要设置两个参数。首先，所有broker必须配置相同的zookeeper.connect，该参数指定了用于保存元数据的ZooKeeper群组和路径。其次，每个broker都必须为broker.id参数设置唯一的值。如果两个broker设置相同的broker.id那么第二个就无法启动。

#### 操作系统调优

调整内核参数来进一步提升Kafka的性能。主要包括虚拟内存、网络子系统和用来存储日志片段的磁盘挂载点有关。一般配置在`/etc/sysctl.conf`文件里。

1.  虚拟内存：一种避免内存交换的方法是不设置任何交换分区。进行内存交换可以防止操作系统由于内存不足而突然终止进程。建议把`vm.swapping`参数的值设置的较小一点，比如1.该参数指明虚拟机的子系统如何使用交换分区，而不是只把内存页从页面缓存里移除。要优先考虑减小页面缓存，而不是进行内存交换。在Linux内核3.5-rcl版本后，0意味着：在任何情况下都不要发生交换。

    调整内核对脏页的处理方式可以从中受益。需要将脏页的数量降低。可以设置`vm.dirty_background_ratio`小于10，一般设置为5.该值表示系统内存的百分比。不应该设为0，这会促使内核频繁地刷新页面，从而降低内核为底层设备的磁盘写入提供缓冲的能力。
    
    通过设置`vm_dirty_ratio`参数可以增加被内核进程刷新到磁盘之前的脏页数量，可以将它设置为大于20的值（也是系统内存的百分比）。60-80是个比较合理的区间。如果参数设置较高的值，建议启用Kafka的复制功能，避免因系统崩溃造成数据丢失。可以通过`/proc/vmstat`文件里查看当前脏页数量。
    
2.  磁盘：目前EXT4和XFS较为常见，其中XFS为Kafka提供了更好的功能。最好对挂载点的`noatime`参数进行合理的设置。文件元数据包括3个时间戳：创建时间`ctime`、最后修改时间`mtime`、最后访问时间`atime`。每次文件读取后都会更新`atime`，会导致大量的磁盘写操作，且作用不大，可以设置`noatime`防止更新`atime`。

3.  网络：首先可以对分分配给socket读写缓冲区的内存大小做出调整。分别是`net.core.wmem_default`和`net.core.rmem_default`，合理的值是131072（128KB）。最大值分别是`net.core.wmem_max`和`net.core.rmem_max`，合理的值是2097152（2MB）。

    另外还可以设置TCP socket的读写缓冲区，分别是`net.ipv4.tcp_wmem`和`net.ipv4.tcp_rmem`。这些参数的值又3个整数组成，使用空格分隔，分别是最小值、默认值和最大值。最大值不能大于`net.core.wmem_max`和`net.core.rmem_max`。另外还可以启用`net.ipv4.tcp_window_scaling`，启用TCP时间窗扩展，可以提升客户端传输数据的效率，传输的数据在服务器端进行缓冲。

### 生产环境的注意事项

#### 共享ZooKeeper

Kafka使用ZooKeeper来保存broker、主题和分区的元数据信息。



## Kafka生产者-向Kafka写入数据

### 生产者概览

创建一个`ProducerRecord`对象开始，该对象需要包含目标主题和要发送的内容。还可以指定键和分区。在发送`ProducerRecord`对象之前，生产者要先把键和值对象序列化成字节数组，才能传输。

接下来数据传给分区器。如果之前指定了分区，则分区器不会做任何事情，直接把指定的分区返回，否则根据键选择分区。选好分区后，生产者知道该往哪个分区发送这条记录。然后将该记录添加到一个记录批次，这个批次里的所有消息被发送到相同的主体和分区上。有一个独立的线程负责把这些记录批次发送到相应的broker上。

服务器在收到这些消息时会返回一个响应。如果成功写入Kafka，返回一个`RecordMetaData`对象，包含主题和分区消息，以及记录在分区里的偏移量。如果写入失败，返回一个错误。生产者在收到错误之后会尝试重新发送消息，几次之后还是失败，返回错误信息。

### 创建生产者

要往Kafka写入消息，首先创建一个生产者对象，并设置一些属性。Kafka生产者有3个必选的属性：

-   bootstrap.servers

    指定broker的地址清单，地址的格式为`host:port`。清单里不需要包含所有的broker地址，生产者会从给定的broker里查找到其他的broker的信息。建议提供两个broker的信息，一旦其中一个宕机，生产者仍然能够连接到集群上。

-   key.serializer

    broker希望接收到的消息的键和值都是字节数组。生产者接口允许使用参数化类型。因此如果有需要，可以设置该序列化器。

-   value.serializer

    与key.serializer一样，将值序列化。

实例化生产者对象后，可以发送消息。发送消息主要有一下3种方式：

-   发送并忘记

    发送消息给服务器，不关心是否正常到达。可能会丢失一些消息

-   同步发送

    使用send方法发送消息，会返回一个Future对象，调用get()方法进行等待，可以知道消息是否发送成功

-   异步发送

    调用send()方法，并指定一个回调函数，服务器在返回响应时调用该函数。

KafkaProducer一般会发生两类错误。其中一类是可重试错误，这类错误可以通过重发消息来解决。比如对于连接错误，可以通过再次建立连接来解决，“无主（no leader）”错误则可以通过重新为分区选举首领来解决。KafkaProducer可以被配置为自动重试，如果在重试后仍无法解决问题，应用程序会收到一个重试异常。另一类错误无法通过重试解决，比如“消息太大”异常。对于这类异常，KafkaProducer不会进行重试，直接抛出异常。

### 生产者的配置

1.  acks：指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。这个参数对消息丢失的可能性有重要影响。该参数有如下选项：
    -   acks=0：生产者在成功写入消息之前不会等待任何来自服务器的响应。如果当中出现问题，导致服务器没有收到消息，生产者就无从得知，消息会丢失。但是由于生产者不需要等待服务器的响应，可以以网络能够支持的最大速度发送消息，从而达到很高的吞吐量。
    -   acks=1：只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应。如果消息无法到达首领节点（比如首领节点崩溃，新的首领节点还没有选举出来），生产者会收到一个错误响应，为了避免数据丢失，生产者会重发消息。如果一个没有收到消息的节点称为新首领，消息还是会丢失。这个时候的吞吐量取决于使用的是同步发送还是异步发送。吞吐量还会受发送中消息数量的限制。
    -   acks=all：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。这种模式是最安全的，可以保证不止一个服务器收到消息，但是延迟比acks=1时更高。
2.  buffer.memory：设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。这时send()方法要么被阻塞，要么抛出异常，取决于如何设置block.on.buffer.full参数。
3.  compression.type：默认情况下不压缩消息。该参数可以被设置为snappy、gzip或lz4.指定消息被发送给broker之前使用哪一种压缩算法进行压缩。使用压缩可以降低网络传输开销和存储开销，这是kafka发送消息的瓶颈。
4.  retries：生产者从服务器收到的错误可能是临时性的错误。该参数值决定了生产者可以重发消息的次数，如果达到次数，生产者会放弃重试并返回错误。默认情况下，每次重试之间会等待100ms，不过可以通过retry.backoff.ms参数来改变这个时间间隔。一般情况下，因为生产者会自动进行重试，所以就没有必要在代码逻辑里处理那些可重试的错误，只需要处理不可重试的错误或重试次数超出上限的情况。
5.  batch.size：当有多个消息需要被发送到同一个分区时，生产者会把它们放到同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算，而不是消息个数。当批次被填满，批次里的所有消息会被发送出去。不过生产者不一定都会等到批次被填满才发送，半满的批次，甚至只包含一个消息的批次也有可能被发送。因此可以稍微设置的大一点。