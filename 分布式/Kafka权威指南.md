# Kafka权威指南

## 初始Kafka

### 发布与订阅消息系统

发布者以某种方式对消息进行分类，接收者订阅它们，以便接收特定类型的消息。发布与订阅系统一般会有一个broker，即发布消息的中心点。

### Kafka登场

Kafka一般被称为“分布式提交日志”或者“分布式流平台”。文件系统或数据库提交日志用来提供所有事务的持久记录，通过重放这些日志可以重建系统的状态。数据是按照一定顺序持久化保存的，可以按需读取，并且具备数据故障保护和性能伸缩能力。

#### 消息和批次

Kafka的数据单元被称为**消息**。消息可以有一个可选的元数据，即**键**。键是一个字节数组。当消息以一种可控的方式写入不同的分区时，会用到键。最简单的例子是位键生成一个一致性散列值，然后使用散列值对主题分区数进行取模，为消息进行分区。保证具有相同键的消息总是被写入到相同的分区。

为了提高效率，消息被分批次写入Kafka。**批次**是一组消息，这些消息属于同一个主题和分区。

#### 模式

消息模式是一种结构用于定义消息内容。模式和消息体是分开的，当模式发生变化，不需要重新生成代码，支持强类型和模式进化，版本向前兼容，也向后兼容。

#### 主题和分区

Kafka的消息通过**主题**进行分类。主题类似数据库的表。主题可以被分为若干个**分区**，一个分区就是一个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取。一个主题由于含有多个分区，整个主题范围内无法保证消息的顺序，但单个分区内的顺序可以保证。Kafka通过分区来实现数据的冗余和伸缩性。分区可以分布在不同的服务器上，即一个主题可以横跨多个服务器。

通常使用**流**来描述Kafka这类系统的数据。把一个主题的数据看成一个流。流是一组从生产者移动到消费者的数据。

#### 生产者和消费者

Kafka 客户端被分为两种基本的类型：生产者和消费者。

**生产者**创建消息。一般情况下，一个消息会被发布到一个特定的主题上。生产者默认情况下把消息均衡地分布到主题的所有分区上，而不关心特定消息会被写到哪个分区。有时可以通过消息键和分区器来把消息直接写到指定的分区。分区器为键生成一个散列值，并将其映射到指定的分区。从而保证同一个键的消息会被写到同一个分区。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。

**消费者**读取消息。订阅一个或多个主题，并将消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，是一个不断递增的整数值，在创建消息时，Kafka会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的消息偏移量保存在ZooKeeper或Kafka上，如果消费者关闭或重启，读取状态不会丢失。

消费者是**消费者群组**的一部分。会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消息者使用。比如某些消费者会使用多个分区，但不会出现一个分区被多个消费者读取。消费者与分区之间的映射被称为消费者对分区的所有权关系。

通过这种方式，消费者可以消费包含大量消息的主题。并且一个消费者失效，群组里其他消费者可以接管失效消费者的工作。

#### broker和集群

一个独立的Kafka服务器被称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。

broker是集群的组成部分。每个集群都有一个broker同时充当了**集群控制器**的角色（自动从集群的活跃成员中选举出来）。控制器负责管理工作，包括将分区分配给broker和监控broker。在集群中，一个分区从属于一个broker，该broker被称为分区的**首领**。一个分区可以分配给多个broker，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余，如果有一个broker失效，其他broker可以接管领导权。不过相关的消费者和生产者需要重新连接到新的首领。

**保留消息**是Kafka的一个重要特性。默认消息保留策略为：

保留一段时间（比如7天），或者保留到消息达到一定大小的字节数（比如1GB）。当消息数量达到这些上限时，旧消息会过期然后被删除。主题可以配置自己的保留策略，可以将消息保留到不再使用它们为止。可以通过配置把主题当做**紧凑型日志**，只有最后一个带有特定键的消息会被保留下来。

#### 多集群

基于以下原因，最好使用多个集群。

-   数据类型分离
-   安全需求隔离
-   多数据中心（灾难恢复）

如果使用多个数据中心，需要在它们之间复制消息。Kafka的消息复制机制只能在单个集群中进行。

Kafka提供一个MirronMaker工具，可以用于集群间的消息复制。核心组件包括一个生产者和消费者，两者之间通过一个队列相连。

### Kafka的优点

#### 多个生产者

Kafka可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题。适合用来从多个前端系统收集数据，并以统一的格式对外提供数据。

#### 多个消费者

Kafka支持多个消费者从一个单独的消息流上读取数据，而且消费者之间互不影响。另外多个消费者之间可以组成一个群组，共享一个消息流，并保证整个群组对每个给定的消息只处理一次。

#### 基于磁盘的数据存储

Kafka允许消费者非实时地读取消息。消息被提交到磁盘，根据设置的规则进行保存。每个主题可以设置单独的保留规则，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。

#### 伸缩性

broker可以不断扩展，对在线集群进行扩展不影响整体系统的可用性。但要提高集群的容灾能力，需要配置较高的复制系数。

#### 高性能

通过横向扩展生产者、消费者和broker，Kafka可以轻松处理巨大的消息流。在处理大量数据的同时，能保证亚秒级的消息延迟。

## 数据生态系统

Kafka为数据生态系统带来循环接口，在基础设施的各个组件之间传递消息，为所有客户端提供一致的接口。当与提供消息模式的系统集成时，生产者和消费者之间不再有紧密的耦合，也不需要在它们之间建立任何类型的直连。可以根据业务需要添加或移除组件。

## 安装Kafka

### broker配置

#### 常规配置

-   broker.id：每个broker都有一个标识符，使用broker.id来表示。默认值是0，可以被设置为其他的任意整数。在整个Kafka集群里必须是唯一的。

-   port：默认监听9092端口。

-   zookeeper.connect：用于保存broker元数据的ZooKeeper地址。该配置参数是由冒号分隔的一组`hostname:port/path`列表。其中`/path`为可选的ZooKeeper路径，作为Kafka集群的chroot环境。如果不指定，默认为根路径。

-   log.dirs：存放日志片段的目录。是一组用逗号分隔的本地文件系统路径。如果指定多个路径，那么broker会根据“最少使用”原则，把同一个分区的日志片段保存到同一个路径下。broker会往拥有最少数目分区的路径新增分区，而不是拥有最小磁盘空间的路径新增分区。

-   num.recovery.threads.per.data.dir：对于如下3种情况，Kafka会使用可配置的线程池来处理日志片段：

    -   服务器正常启动，用于打开每个分区的日志片段
    -   服务器崩溃后重启，用于检查和截断每个分区的日志片段
    -   服务器正常关闭，用于关闭日志片段

    默认情况下，每个日志片段只使用一个线程。这些线程只是在服务器启动和关闭时会用到，可以设置大量的线程来达到并行操作的目的。设置的数字对应的是log.dirs指定的单个日志目录。假如设置的参数为8，log.dirs指定了3个路径，总共需要24个线程。

-   auto.create.topics.enable：默认情况下，Kafka会在如下几种情况下自动创建主题：

    -   当一个生产者开始往主题写入消息时
    -   当一个消费者开始从主题读取消息时
    -   当任意一个客户端向主题发送元数据请求时

    根据Kafka协议，如果一个主题不先被创建，根本无法知道它是否已经存在，因此可以设置为false。

#### 主题的默认配置

-   num.partitions：指定新创建的主题将包含的分区数。可以增加主题分区的个数，但不能减少。如果要让一个主题的分区个数少于该值，需要手动创建主题。

    选定分区数量：

    -   主题需要达到多大的吞吐量
    -   从单个分区读取数据的最大吞吐量是多少
    -   估算生产者向单个分区写入数据的吞吐量，可以多估算一些
    -   每个broker包含的分区个数、可用的磁盘空间和网络带宽
    -   如果消息按照不同的键来写入分区，为已有的主体新增分区会很困难
    -   单个broker对分区个数有限制，因为分区越多，占用的内存越多，完成首领选举需要的时间越长

-   log.retention.ms：Kafka根据时间来决定数据可以被保留多久。默认使用log.retention.hours参数配置，默认值为168小时，即一周。另外还有log.retention.ms和log.retention.minutes，如果配置多个，取最小值。

    根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现的。

-   log.retention.bytes：另一种方式通过保留的消息字节数来判断消息是否过期。作用在每一个分区上。如果有一个主题含有8个分区，并且该值设置为1G，这个主题最多可以保留8G的数据。当主题的分区个数增加时，整个主题保留的数据随之增加。

    如果同时指定log.retention.ms和log.retention.bytes，只要满足任意一个条件就会删除产品。

-   log.segment.bytes：当日志片段大小达到log.segment.bytes指定的上限（默认是1G），当前日志片段就会被关闭，一个新的日志片段被打开。如果一个日志片段被关闭，就开始等待过期。这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率。

    日志片段的大小会影响使用时间戳获取偏移量。在使用时间戳获取日志偏移量时，Kafka会检查分区里最后修改时间大于指定时间戳的日志片段（已经被关闭的），该日志片段的前一个文件的最后修改时间小于指定时间戳。然后Kafka返回该日志片段开头的偏移量。对于使用时间戳获取偏移量的操作来说，日志片段越小，结果越准确。

-   log.segment.ms：指定多长时间之后日志片段会被关闭。

    在使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性能的影响。如果多个分区的日志片段永远不能达到大小的上限，在broker启动之后就会计算日志片段的过期时间，可能同时关闭多个日志片段。

-   message.max.bytes：限制单个消息的大小，默认值是1000000，即1MB。如果超过限制，消息不会被接收，还会收到broker返回的错误信息。指的是压缩后的大小。对性能有显著的影响。

    消费者客户端设置的fetch.message.max.bytes必须与服务器端设置的消息大小进行协调。如果比message.max.bytes小，那么消费者就无法读取比较大的消息，导致出现消费者被阻塞的情况。为集群broker配置replica.fetch.bytes参数时，也遵循同样的原则。

### 硬件的选择

#### 磁盘吞吐量

生产者客户端的性能直接受到服务器端磁盘吞吐量的影响。

#### 磁盘容量

通过让主题拥有多个分区，集群的总流量可以被均衡到整个集群，如果单个broker无法支撑全部容量，可以让其他broker提供可用的容量。

#### 内存

内存主要影响消费者。消费者一般从分区尾部读取消息，如果有生产者存在，就紧跟在生产者后面。此时，消费者读取的消息会直接存放在系统的页面缓存里。

另外还有网络和CPU。

### Kafka集群

#### 需要多少个broker

首先，需要多少磁盘空间来保留数据，单个broker有多少空间可用。此外，需要考虑集群处理请求的能力。如果单个broker的网络接口在高峰时段可以达到80%的使用量，并且有两个消费者，那么消费者就无法保持峰值，除非有两个broker。如果启用复制功能，要把额外的消费者考虑在内。

#### broker配置

把broker加入到集群，需要设置两个参数。首先，所有broker必须配置相同的zookeeper.connect，该参数指定了用于保存元数据的ZooKeeper群组和路径。其次，每个broker都必须为broker.id参数设置唯一的值。如果两个broker设置相同的broker.id那么第二个就无法启动。

#### 操作系统调优

调整内核参数来进一步提升Kafka的性能。主要包括虚拟内存、网络子系统和用来存储日志片段的磁盘挂载点有关。一般配置在`/etc/sysctl.conf`文件里。

1.  虚拟内存：一种避免内存交换的方法是不设置任何交换分区。进行内存交换可以防止操作系统由于内存不足而突然终止进程。建议把`vm.swapping`参数的值设置的较小一点，比如1.该参数指明虚拟机的子系统如何使用交换分区，而不是只把内存页从页面缓存里移除。要优先考虑减小页面缓存，而不是进行内存交换。在Linux内核3.5-rcl版本后，0意味着：在任何情况下都不要发生交换。

    调整内核对脏页的处理方式可以从中受益。需要将脏页的数量降低。可以设置`vm.dirty_background_ratio`小于10，一般设置为5.该值表示系统内存的百分比。不应该设为0，这会促使内核频繁地刷新页面，从而降低内核为底层设备的磁盘写入提供缓冲的能力。
    
    通过设置`vm_dirty_ratio`参数可以增加被内核进程刷新到磁盘之前的脏页数量，可以将它设置为大于20的值（也是系统内存的百分比）。60-80是个比较合理的区间。如果参数设置较高的值，建议启用Kafka的复制功能，避免因系统崩溃造成数据丢失。可以通过`/proc/vmstat`文件里查看当前脏页数量。
    
2.  磁盘：目前EXT4和XFS较为常见，其中XFS为Kafka提供了更好的功能。最好对挂载点的`noatime`参数进行合理的设置。文件元数据包括3个时间戳：创建时间`ctime`、最后修改时间`mtime`、最后访问时间`atime`。每次文件读取后都会更新`atime`，会导致大量的磁盘写操作，且作用不大，可以设置`noatime`防止更新`atime`。

3.  网络：首先可以对分分配给socket读写缓冲区的内存大小做出调整。分别是`net.core.wmem_default`和`net.core.rmem_default`，合理的值是131072（128KB）。最大值分别是`net.core.wmem_max`和`net.core.rmem_max`，合理的值是2097152（2MB）。

    另外还可以设置TCP socket的读写缓冲区，分别是`net.ipv4.tcp_wmem`和`net.ipv4.tcp_rmem`。这些参数的值又3个整数组成，使用空格分隔，分别是最小值、默认值和最大值。最大值不能大于`net.core.wmem_max`和`net.core.rmem_max`。另外还可以启用`net.ipv4.tcp_window_scaling`，启用TCP时间窗扩展，可以提升客户端传输数据的效率，传输的数据在服务器端进行缓冲。

### 生产环境的注意事项

#### 共享ZooKeeper

Kafka使用ZooKeeper来保存broker、主题和分区的元数据信息。



## Kafka生产者-向Kafka写入数据

### 生产者概览

创建一个`ProducerRecord`对象开始，该对象需要包含目标主题和要发送的内容。还可以指定键和分区。在发送`ProducerRecord`对象之前，生产者要先把键和值对象序列化成字节数组，才能传输。

接下来数据传给分区器。如果之前指定了分区，则分区器不会做任何事情，直接把指定的分区返回，否则根据键选择分区。选好分区后，生产者知道该往哪个分区发送这条记录。然后将该记录添加到一个记录批次，这个批次里的所有消息被发送到相同的主体和分区上。有一个独立的线程负责把这些记录批次发送到相应的broker上。

服务器在收到这些消息时会返回一个响应。如果成功写入Kafka，返回一个`RecordMetaData`对象，包含主题和分区消息，以及记录在分区里的偏移量。如果写入失败，返回一个错误。生产者在收到错误之后会尝试重新发送消息，几次之后还是失败，返回错误信息。

### 创建生产者

要往Kafka写入消息，首先创建一个生产者对象，并设置一些属性。Kafka生产者有3个必选的属性：

-   bootstrap.servers

    指定broker的地址清单，地址的格式为`host:port`。清单里不需要包含所有的broker地址，生产者会从给定的broker里查找到其他的broker的信息。建议提供两个broker的信息，一旦其中一个宕机，生产者仍然能够连接到集群上。

-   key.serializer

    broker希望接收到的消息的键和值都是字节数组。生产者接口允许使用参数化类型。因此如果有需要，可以设置该序列化器。

-   value.serializer

    与key.serializer一样，将值序列化。

实例化生产者对象后，可以发送消息。发送消息主要有一下3种方式：

-   发送并忘记

    发送消息给服务器，不关心是否正常到达。可能会丢失一些消息

-   同步发送

    使用send方法发送消息，会返回一个Future对象，调用get()方法进行等待，可以知道消息是否发送成功

-   异步发送

    调用send()方法，并指定一个回调函数，服务器在返回响应时调用该函数。

KafkaProducer一般会发生两类错误。其中一类是可重试错误，这类错误可以通过重发消息来解决。比如对于连接错误，可以通过再次建立连接来解决，“无主（no leader）”错误则可以通过重新为分区选举首领来解决。KafkaProducer可以被配置为自动重试，如果在重试后仍无法解决问题，应用程序会收到一个重试异常。另一类错误无法通过重试解决，比如“消息太大”异常。对于这类异常，KafkaProducer不会进行重试，直接抛出异常。

### 生产者的配置

1.  acks：指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。这个参数对消息丢失的可能性有重要影响。该参数有如下选项：
    -   acks=0：生产者在成功写入消息之前不会等待任何来自服务器的响应。如果当中出现问题，导致服务器没有收到消息，生产者就无从得知，消息会丢失。但是由于生产者不需要等待服务器的响应，可以以网络能够支持的最大速度发送消息，从而达到很高的吞吐量。
    -   acks=1：只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应。如果消息无法到达首领节点（比如首领节点崩溃，新的首领节点还没有选举出来），生产者会收到一个错误响应，为了避免数据丢失，生产者会重发消息。如果一个没有收到消息的节点称为新首领，消息还是会丢失。这个时候的吞吐量取决于使用的是同步发送还是异步发送。吞吐量还会受发送中消息数量的限制。
    -   acks=all：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。这种模式是最安全的，可以保证不止一个服务器收到消息，但是延迟比acks=1时更高。
2.  buffer.memory：设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。这时send()方法要么被阻塞，要么抛出异常，取决于如何设置block.on.buffer.full参数。
3.  compression.type：默认情况下不压缩消息。该参数可以被设置为snappy、gzip或lz4.指定消息被发送给broker之前使用哪一种压缩算法进行压缩。使用压缩可以降低网络传输开销和存储开销，这是kafka发送消息的瓶颈。
4.  retries：生产者从服务器收到的错误可能是临时性的错误。该参数值决定了生产者可以重发消息的次数，如果达到次数，生产者会放弃重试并返回错误。默认情况下，每次重试之间会等待100ms，不过可以通过retry.backoff.ms参数来改变这个时间间隔。一般情况下，因为生产者会自动进行重试，所以就没有必要在代码逻辑里处理那些可重试的错误，只需要处理不可重试的错误或重试次数超出上限的情况。
5.  batch.size：当有多个消息需要被发送到同一个分区时，生产者会把它们放到同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算，而不是消息个数。当批次被填满，批次里的所有消息会被发送出去。不过生产者不一定都会等到批次被填满才发送，半满的批次，甚至只包含一个消息的批次也有可能被发送。因此可以稍微设置的大一点。

## 深入Kafka

### 集群成员关系

Kafka使用ZooKeeper来维护集群成员的信息。每个broker都有一个唯一标识符，这个标识符可以在配置文件中指定，也可以自动生成。在broker启动的时候，通过创建临时节点把自己的ID注册到ZooKeeper。Kafka组件订阅ZooKeeper的`/broker/ids`路径（broker在ZooKeeper上的注册路径），当有broker加入集群或退出集群时，这些组件就可以获得通知。

如果启动一个相同ID的broker，会得到一个错误-新broker会试着进行注册，但不会成功。

在broker停机、出现网络分区或长时间垃圾回收停顿时，broker会从ZooKeeper上断开连接，此时broker在启动时创建的临时节点会自动从ZooKeeper上移除。监听broker列表的Kafka组件会被告知该broker已移除。在关闭broker时，对应的节点也会消失，不过它的ID会继续存在于其他数据结构中。例如，主题的副本列表里就可能包含这些ID。在完全关闭一个broker后，如果使用相同的ID启动另一个全新的broker，会立即加入集群，并拥有与旧broker相同的分区和主题。

### 控制器

控制器就是一个broker，但是还负责分区首领的选举。集群里第一个启动的broker通过在ZooKeeper里创建一个临时节点`/controller`让自己成为控制器。其他broker在启动时也会尝试创建这个节点，但是创建失败，表明集群里已经有一个控制器。然后其他broker会在控制器节点创建一个ZooKeeper watch对象，监听这个节点。

如果控制器被关闭或者与ZooKeeper断开连接，该临时节点被删除，其他的broker会尝试创建新的控制节点。每个新的控制节点会通过ZooKeeper的条件递增操作获得一个全新的、数值更大的controller epoch。其他broker在知道当前controller epoch后，如果收到由控制器发出的包含较旧epoch的消息，就会忽略。

如果控制器发现一个broker离开集群，那些首领在这个broker上的分区需要一个新的首领。控制器遍历这些分区，并确定谁应该成为新的首领，然后向所有包含新首领或现有跟随者的broker发送请求。该请求消息包含谁是新首领及谁是分区跟随者的信息。随后，新首领开始处理来自生产者和消费者的请求，跟随者开始从新首领那里复制消息。

当控制器发现一个新的broker加入集群，会使用brokerID来检查新加入的broker是否包含现有分区的副本，如果有，控制器会把变更通知发送给新加入的broker和其他的broker，新broker上的副本开始从首领那里复制消息。

控制器使用epoch来避免”脑裂“。

### 复制

复制功能是Kafka的核心。Kafka使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本。那些副本被保存在broker上，每个broker上可以保存成百上千个属于不同主题和分区的副本。

副本有一下两种类型：

-   首领副本

    每个分区都有一个首领副本。为了保证一致性，所有生产者和消费者请求都会经过这个副本。

-   跟随者副本

    首领意外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求，唯一的任务就是从首领那里复制消息，保持与首领一致的状态。如果首领崩溃，其中的一个跟随者会被提升为新首领。

首领的另一个任务是搞清楚哪个跟随者的状态与自己是一致的。跟随者为了保持与首领的状态一致，在有新消息到达时尝试从首领那里复制消息，不过有各种原因导致同步失败。

为了与首领保持同步，跟随者向首领发送获取数据的请求，这种请求与消费者为了读取消息而发送的请求时一样的，首领将响应消息发送给跟随者。请求消息里包含了跟随者想要获取消息的偏移量，而且这些偏移量是有序的。

通过查看每个跟随者请求的最新偏移量，首领就会知道每个跟随者复制的进度。如果跟随者在10s内没有请求消息，或者虽然在请求数据，但是在10s内没有请求最新的数据，就会认为是不同步的。如果一个副本无法与首领保持一致，在首领失效时，就不能成为新首领。

持续请求得到最新消息副本被称为同步的副本。在首领失效时，只有同步副本才有可能被选为新首领。

跟随者的正常不活跃时间或在称为不同步副本之前的时间是通过`replica.lag.time.max.ms`参数来配置。这个时间间隔直接影响首领选举期间的客户端行为和数据保留机制。

除了当前首领之外，每个分区都有一个首选首领-创主题时选定的首领就是分区的首选首领。因为在创建分区时，需要在broker之间均衡首领。因此，希望首选首领在称为真正的首领时，broker间的负载最终会得到均衡、默认`auto.leader.rebalance`开启，会检查首选首领是不是当前首领，如果不是，并且该副本是同步的，那么就触发首领选举，让首选首领成为当前首领。

### 处理请求

Kafka提供了一个二进制协议，指定了请求消息的格式以及broker如何对请求作出响应-包括成功处理请求或在处理请求过程中遇到错误。客户端发起连接并发送请求，broker处理请求并作出响应。broker按照请求到达的顺序来处理它们-这种顺序保证Kafka具有了消息队列的特性，同时保证保存的消息是有序的。

所有的请求信息都包含一个标准消息头：

-   Request type（也就是API Key）
-   Request version（broker可以处理不同版本的客户端请求，并根据客户端版本作出不同的响应）
-   Correlation ID-一个具有唯一性的数字，用于标识请求信息，同时也会出现在响应信息和错误日志里（用于诊断问题）
-   Client ID-用于标识发送请求的客户端

常见的请求类型：

-   生产请求：生产者发送的请求，包含客户端要写入broker的消息
-   获取请求：在消费者和跟随者副本需要从broker读取消息时发送的请求

生产请求和获取请求都必须发送给分区的首领副本。如果broker收到一个针对特定分区的请求，而该分区的首领在另一个broker上，那么发送请求的客户端会收到一个“非分区首领”的错误响应。当针对特定分区的获取请求被发送一个不含有该分区首领的broker上，也会出现同样的错误。Kafka客户端需要自己负责把生产请求和获取请求发送到正确的broker上。

客户端可以使用**元数据请求**获取感兴趣的主题列表。对应的响应消息指明了这些主题所包含的分区、每个分区都有哪些副本，以及哪些副本是首领。元数据请求可以发送给任何一个broker，所有的broker都缓存了这些消息。

一般情况下，客户端会缓存这些信息，并且时不时刷新，时间间隔通过`metadata.max.age.ms`参数配置。

#### 生产请求

根据ack的配置情况，分为三种情形：acks=0,acks=1,acks=-1/all。包含首领副本的broker在收到生产请求时，会对请求做一些验证：

-   发送数据的用户是否有主题写入权限
-   请求里包含的acks值是否有效
-   如果acks=all，是否有足够多的同步副本保证消息已经被安全写入

之后，消息会被写入到本地磁盘。Kafka不会一直等待数据被写到磁盘上-依赖复制功能来保证消息的持久性。

在消息被写入分区的首领之后，broker开始检查acks配置参数-如果acks被设为0或1，那么broker立即返回响应；如果acks被设为all，那么请求会被保存在一个叫做**炼狱**的缓冲区里，直到首领发现所有跟随者副本都复制了消息，响应才会被返回给客户端。

#### 获取请求

broker处理获取请求的方式与处理生产请求的方式相似。客户端可以指定主题分区里特定偏移量的消息。Kafka使用零复制技术向客户端发送消息-将消息从文件里发送到网络通道，不需要经过任何中间缓冲区。

但是不是所有保存在分区首领上的数据都可以被客户端读取。大部分客户端只能读取已经被写入所有同步副本的消息（跟随者副本也不行）。分区首领知道每个消息会被复制到哪个副本上，在消息还没有被写入到所有同步副本之前，不会发送给消费者-尝试获取这些消息的请求会得到空的响应，而不是错误。

因为没有足够多的副本复制的消息被认为是“不安全”的-如果首领发生崩溃，另一个副本称为新首领，那么这些消息就会丢失，会破坏一致性。延迟时间可以通过`replica.lag.time.max.ms`指定副本在复制消息时可被允许的最大延迟时间。

#### 其他请求

当一个新首领被选举出来，控制器会发送`LeaderAndIsr`请求给新首领（这样就可以接收来自客户端的请求）和跟随者（知道开始跟随新首领）。

### 物理存储

Kafka的基本存储单元是分区。分区无法在多个broker间进行再细分，也无法在同一个broker的多个磁盘上进行再细分。所以，分区的大小受到单个挂载点可用空间的限制。配置Kafka的时候，通过`log.dirs`参数的值指定每个挂载点的目录。

#### 分区分配

在创建主题时，Kafka首先在broker间平均地分布副本，并且每个分区的每个副本分布在不同的broker上，如果指定了broker的机架信息，尽量使每个分区的副本分配到不同机架的broker上。

选好合适的broker后，单独为每个分区分配目录。计算每个目录的分区数量，新的分区总是被添加到数量最小的目录里。但是没有考虑可用空间和工作负载的问题。

#### 文件管理

保留数据是Kafka的一个基本特性。分区分成若干个**片段**。默认情况下，每个片段包含1GB或一周数据，以较小的为准。如果达到片段上限，就关闭当前文件，并打开一个新文件。

当前正在写入的片段称为**活跃片段**。活跃片段永远不会被删除。broker会为分区里的每个片段打开一个文件句柄，哪怕片段不活跃，这样会导致打开过多的文件句柄，需要做调优。

#### 文件格式

保存在磁盘上的数据格式与从生产者发送过来或者发送给消费者的消息格式是一样的。因此可以使用零拷贝技术给消费者发送消息，同时避免了对生产者已经压缩过的消息进行解压和再压缩。

消息里包含：偏移量、魔术数、压缩和解压、时间戳、键的大小、键、值的大小、值。

如果是压缩过的消息，同一个批次的消息被压缩在一起，当做“包装消息”进行发送。这里面含有每个消息的时间戳和偏移量。

如果生产者端使用压缩功能，那么发送的批次越大，意味着网络传输和磁盘存储方面获得越好的压缩性能，意味着如果修改了消费者使用的消息格式，那么网络传输和磁盘存储的格式也要随之修改，而且broker要知道如何处理包含了两种消息格式的文件。

#### 索引

Kafka为每个分区维护一个索引。索引把偏移量映射到片段文件和偏移量在文件里的位置。

索引也被分成片段，所以在删除消息时，可以删除相应的索引。Kafka不维护索引的校验和。如果索引出现损坏，会重新读取消息并录制偏移量和位置来重新生成索引。因此删除索引是绝对安全的。

#### 清理

为主题设置`compact`策略可以将早于保留时间的旧事件删除，为每个键保留最新的值，从而达到清理的效果。

#### 清理的工作原理

每个日志片段分为：

-   干净的部分：这些消息之前被清理过，每个键只有一个对应的值，这个值是上一次清理时保留下来的
-   污浊的部分：这些消息时上一次清理之后写入的。

Kafka通过配置`log.clanner.enabled`参数启用清理功能。每个broker会启动一个清理管理器线程和多个清理线程，负责执行清理任务。选择污浊率较高的分区进行清理。

首先创建一个map，然后读取污浊的部分，保证map里是污浊部分的每个键的最新值。然后读取分区的干净部分，从最旧的消息开始，如果map里没有，就把消息复制替换片段，否则就不替换。直到所有键的最新值都写到替换片段，然后将原始片段和替换片段进行交换。

#### 被删除的事件

如果要把一个键从系统里删除，应用程序必须发送一个包含该键且值为null的消息。该消息被称为墓碑消息。

#### 何时清理主题

一般在脏记录的主题数量达到50%时进行清理



## 可靠的数据传递

### 可靠性保证

-   Kafka可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入，那么Kafka可以保证消息B的偏移量比消息A的偏移量大，那么消费者会先读取消息A再读取消息B。
-   只有当消息被写入分区的所有同步副本时（但不一定写入磁盘），才被认为是“已提交的”。生产者可以选择接受不同类型的确认。
-   只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。
-   消费者只能读取已经被提交的消息。

### 复制

分区首领是同步副本，对于跟随者副本来说，需要满足以下条件才被认为是同步的。

-   与ZooKeeper之间有一个活跃的会话，即在过去的6s（可配置）内向ZooKeeper发送过心跳。
-   在过去的10s内（可配置）从首领那里获取过消息。
-   在过去的10s内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，必须几乎零延迟的。

如果不满足上面的任意一点，就是不同步副本，可以与ZooKeeper重新建立连接，并从首领那里获取最新消息，重新变为同步的。

**非同步副本**：如果一个或多个副本在同步或非同步状态之间快速切换，说明集群内部出现了问题。

一个滞后的同步副本会导致生产者和消费者变慢，因为在消息被认为已提交之前，客户端会等待所有同步副本接收消息。

### broker配置

broker有3个配置参数会影响Kafka消息存储的可靠性。可以应用在broker级别，用于控制所有主题的行为，也可以应用在主题级别，用于控制个别主题的行为。

#### 复制系数

主题级别的配置参数是`replication.factor`，在broker级别可以通过`default.replication.factor`来配置自动创建的主题。

Kafka的默认复制系数是3，即每个分区总共会被3个不同的broker复制3次。可以在主题创建之后，通过新增或移除副本来改变复制系数。

如果复制系数为N，在N-1个broker失效的情况下，仍然能够从主题读取数据或向主题写入数据。更高的复制系数会带来更高的可用性、可靠性和更少的故障。但会占用更多的磁盘空间。

副本的分布也很重要。默认情况下，Kafka会确保分区的每个副本被放在不同的broker上。另外可以用`broker.rack`参数为每个broker配置所在机架的名字。如果配置了机架的名字，Kafka会保证分区的副本被分布在多个机架上，从而获得更高的可用性。

#### 不完全的首领选举

`unclean.leader.election`只能在broker级别进行配置，默认是true。

如果首领不可用，选举过程中没有丢失数据，称这次选举是“完全”的。

如果所有副本都是不同步的，可以做出以下两种选择：

-   如果不同步的副本不能被提升为新首领，那么分区在旧首领（最后一个同步副本）恢复之前是不可以的。
-   如果不同步的副本被提升为新首领，在这个副本变为不同步之后写入旧首领的消息会全部丢失，导致数据不一致。

如果把`unclean.leader.election.enable`设为true，那么就会允许不同步的副本称为首领，面临丢失消息的风险。如果设为false，降低了可用性。

#### 最少同步副本

在主题和broker级别上，这个参数都是`min.insync.replicas`。

如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点的值。如果同步副本低于这个值，就会导致broker停止接受生产者的请求。消费者仍然可以继续读取已有的数据。

### 在可靠的系统里使用生产者

-   根据可靠性需求配置适当的acks值
-   在参数配置和代码里正确处理错误

#### 发送确认

-   acks=0：如果生产者通过网络把消息发送出去，就认为消息已经被写入kafka。此时可能会丢失消息，即使开启了完全首领选举，也可能会丢失消息，即在新首领选举过程中并不知道首领已经不可用。
-   acks=1：首领在收到消息并把它写入到分区数据文件（不一定写入到磁盘）时会返回确认或错误响应。此时虽然在新首领选举过程中通过代码避免丢失消息，但也有可能在写入首领后，但复制到其他副本之前首领发生崩溃。
-   acks=all：首领在返回确认或错误响应之前，会等待所有同步副本都收到消息，再和min.insync.replicas参数结合，可以决定在返回确认前至少有多少个副本能够收到消息。可以通过使用异步模式和更大的批次来加快速度。

#### 配置生产者的重试参数

生产者需要处理的错误包括两部分：生产者自动处理的错误和开发者手动处理的错误。

如果可以通过**重试**解决，生产者会自动处理错误。生产者向broker发送消息时，broker可以返回一个成功响应码或错误响应码。错误响应码可以分为两种：重试之后可以解决，无法通过重试解决。如果是不丢失任何消息，最好让生产者在遇到可重试错误时保持重试。重试发送一个已经失败的消息会带来一些风险，如果两个消息都写入成功，会导致消息重复。

#### 额外错误处理

-   不可重试的broker错误
-   在消息发送之前发生的错误，例如序列化错误
-   在生产者达到重试次数上限时或者在消息占用的内存达到上限时发生的错误

### 在可靠的系统里使用消费者

消费者唯一要做的是跟踪哪些消息是已经读取过的，哪些是还没有被读取的。这是在读取消息时不丢失消息的关键。

在从分区读取数据时，消费者会获取一批事件，检查这批事件里最大的偏移量，然后从这个偏移量开始读取另一批事件，保证消费者总能以正确的顺序获取新数据，不会错误任何事件。

如果一个消费者退出，另一个消费者需要知道从什么地方开始继续处理，需要知道前一个消费者在退出前处理的最后一个偏移量是多少。这也可以是自身重启之后重新回来工作。如果消费者提交了偏移量却未能处理完消息，那么就有可能造成消息丢失，这也是消费者丢失消息的主要原因。

**已提交消息与已提交偏移量**：已提交消息是指已经被写入所有同步副本并且对消息者可见的消息，已提交偏移量是指消费者发送给Kafka的偏移量，用于确认它已经收到并处理好的消息位置。

#### 消费者的可靠性配置

-   group.id：如果两个消费者具有相同的group.id，并且订阅了同一个主题，那么每一个消费者会分到主题分区的一个子集，即它们只能读到所有消息的一个子集，如果希望消费者看到主题的所有消息，需要设置唯一的group.id。
-   auto.offset.reset：指定了没有偏移量可提交时或者请求的偏移量在broker上不存在时，消费者会做什么。一个是earliest，从分区的开始位置读取数据。一种是latest，从分区的末尾开始读取数据。
-   enable.auto.commit：非常重要的参数。可以让消费者基于任务调度自动提交偏移量，也可以在代码里手动提交偏移量。
-   auto.commit.interval.ms：与第3个参数有直接的联系。通过该参数配置提交的频率，默认值是5秒提交一次。

#### 显式提交偏移量

1.  总是在处理完事件后再提交偏移量
2.  提交频度是性能和重复消息数量之间的权衡
3.  确保对提交的偏移量心里有数
4.  再均衡
5.  消费者可能需要重试
    -   在遇到可重试错误时，提交最后一个处理成功的偏移量，然后把还没有处理好的消息保存到缓冲区里，调用消费者的pause()方法来确保其他的轮询不会反悔数据，在保持轮询的同时尝试重新处理。如果重试成功，或者重试次数达到上限并决定放弃，那么把错误记录下来并丢弃消息，然后调用resume()方法让消费者继续从轮询里获取新数据
    -   在遇到可重试错误时，把错误写入到一个独立的主体，然后继续。一个独立的消费者群组负责从该主题上读取错误消息并进行重试，不过在重试时需要暂停该主题。
6.  消费者可能需要维护状态
7.  长时间处理
8.  仅一次传递：实现仅一次处理的方法可以是把结果写到一个支持唯一键的系统里，比如键值存储引擎、关系型数据库、ES等。要么消息本身包含一个唯一键，要么使用主题、分区和偏移量的组合来创建唯一键。

### 验证系统可靠性

#### 配置验证

-   验证配置是否满足需求
-   帮助理解系统的行为，了解系统的真正行为是什么，了解对Kafka基本准则的理解是否存在偏差，然后加以改进，同时了解这些准则是如何被应用到各种场景里。

一般包括：

-   首领选举
-   控制器选举
-   依次重启
-   不完全首领选举

#### 应用程序验证

在确定broker和客户端的配置可以满足需求后，接下来验证应用程序是否能够保证达到预期。应用程序的验证包括检查自定义的错误处理代码、偏移量提交的方式、再均衡监听器以及其他使用了Kafka客户端的地方。一般包括：

-   客户端从服务器断开连接
-   首领选举
-   依次重启broker
-   依次重启消费者
-   依次重启生产者

#### 在生产环境监控可靠性

对于生产者来说，最重要的两个可靠性指标是消息的error-rate和retry-rate。如果这两个指标上升，说明系统出现问题。此外还要监控生产者日志。如果消息剩余的重试次数为0，说明生产者已经没有多余的重试机会。

对于消费者来说，最重要的指标是consumer-lag，该指标表明了消费者的处理速度与最近提交到分区里的偏移量之间还有多少差距。理想情况下，该指标总是为0，消费者总能读取到最新的消息。

监控数据流是为了确保所有生成的数据会被及时地读取。通过时间戳，知道数据是什么时候生成的，有助于诊断问题。

为了确保所有消息能够在合理的时间内被读取，应用程序需要记录生成消息的数量，而消费者需要记录已读取消息的数量以及消息生成时间到当前时间之间的时间差。然后，需要使用工具来比较生产者和消费者记录的消息数量（确保没有丢失消息），确保两者之间的时间差不会超过我们允许的范围。另外可以增加一个“监控消费者”来准确地监控生产者。



## 构建数据管道

使用Kafka构建数据管道时，主要有以下两种使用场景：

-   把Kafka作为数据管道的两个端点之一
-   把Kafka作为数据管道两个端点的中间媒介

Kafka可以作为数据管道各个数据段之间的大型缓冲区，有效地解耦管道数据的生产者和消费者。

### 构建数据管道时需要考虑的问题

#### 及时性

Kafka作为一个基于流的数据平台，提供了可靠且可伸缩的数据存储，可以支持几进实时的数据管道和基于小时的批处理。

Kafka主要扮演一个大型缓冲区的角色，降低了生产者和消费者之间的时间敏感度。实时的生产者和基于批处理的消费者可以同时存在，也可以任意组合。Kafka本身使用回压策略（必要时可以延后向生产者发送确认），消费速率完全取决于消费者自己。

#### 可靠性

一般分为**至少一次传递**和**仅一次传递**两种情况。

#### 高吞吐量和动态吞吐量

Kafka支持多种类型的压缩，在增长吞吐量时，Kafka用户和管理员可以通过压缩来调整网络和存储资源的使用。

#### 数据格式

数据管道需要协调各种数据格式和数据类型，这是数据管道的一个非常重要的因素。Kafka和Connect API与数据格式无关。

通用数据集成框架不仅要支持各种不同的数据类型，而且要处理好不同数据源和数据池之间的行为差异。

#### 转换

数据转换比其他需求更具争议性。数据管道的构建分为两大阵营：

-   ETL：提取-转换-加载。当数据流经数据管道时，数据管道会负责处理它们。
-   ELT：提取-加载-转换。数据管道只做少量的转换（主要是数据类型转换），确保到达数据池的数据尽可能地与数据源保持一致。这种情况也被称为高保真数据管道或数据湖架构。

#### 安全性

主要关心如下几个方面：

-   能否保证流经数据管道的数据是经过加密的？这是跨数据中心数据管道通常需要考虑的一个主要方面。
-   谁能够修改数据管道？
-   如果数据管道需要从一个不受信任的位置读取或写入数据，是否有适当的认证机制？

Kafka支持加密传输数据，从数据源到Kafka，再从Kafka到数据池。还支持认证（通过SASL来实现）和授权。如果一个主题包含了敏感信息，在不经授权的情况下，数据是不会流到不安全的系统里的。Kafka还提供了审计日志用于跟踪访问记录。通过编写额外的代码，可能跟踪到每个事件的来源和事件的修改者，从而在每个记录之间建立起整体的联系。

#### 故障处理能力

Kafka会长时间地保留数据，可以在适当的时候重新处理出错的数据。

#### 耦合性和灵活性

数据管道最重要的作用之一是解耦数据源和数据池。在很多情况下可能发生耦合：

-   临时数据管道
-   元数据丢失
-   末端处理

### 如何在Connect API和客户端API之间做出选择

如果要将Kafka连接到数据存储系统，可以使用Connect。用于从外部数据存储系统读取数据或将数据推送到外部存储系统。

如果要连接的数据存储系统没有相应的连接器，可以使用客户端API或Connect API开发，首选Connect API，提供了一些开箱即用的特性。

### Kafka Connect

Connect是Kafka的一部分，为在Kafka和外部数据存储系统之间移动数据提供了一种可靠且可伸缩的方式。为连接器插件提供了一组API和一个运行时-Connect负责运行这些插件，它们负责移动数据。Connect以worker进程集群的方式运行，基于worker进程安装连接器插件，然后使用REST API来管理和配置connector。连接器启动额外的task，有效地利用工作节点的资源，以并行的方式移动大量的数据。数据源的连接器负责从源系统读取数据，并把数据对象提供给worker进程。数据池的连接器负责从worker进程获取数据，并把它们写入目标系统。Connect通过connector在Kafka里存储不同格式的数据。

#### 运行Connect

Connect进程有以下几个重要的配置参数：

-   bootstrap.servers：列出将要与Connect协同工作的broker服务器，连接器会向这些broker写入数据或者从它们那里读取数据。不需要指定集群所有的broker，但至少指定3个。
-   group.id：具有相同group.id的worker属于同一个Connect集群。集群的连接器和它们的任务可以运行在任意一个worker上。
-   key.converter和value.converter：Connect可以处理存储在Kafka里的不同格式的数据，这两个参数分别指定了消息的键和值所使用的转换器。默认使用Kafka提供的JSONConverter。

一般通过Connect的REST API来配置和监控rest.host.name和rest.port连接器。

#### 深入理解Connect

1.  连接器和任务

    连接器插件实现了Connector API，API包含了两部分内容：

    -   连接器：连接器负责3件事情：
        -   决定需要运行多少个任务
        -   按照任务来拆分数据复制
        -   从worker进程获取任务配置并将其传递下去
    -   任务：负责将数据移入或移除kafka。任务再初始化时会得到worker进程分配的一个上下文：源系统上下文包含了一个对象，可以将源系统记录的偏移量保存在上下文里。目标系统连接器的上下文提供了一些方法，连接器可以用它们操作从Kafka接受到的数据，比如进行数据清理、错误重试，或者将偏移量保存到外部系统以便实现仅一次传递。任务在完成初始化之后，就可以按照连接器指定的配置（包含在一个Properties对象里）启动工作。源系统任务对外部系统进行轮询，并返回一些记录，worker进程将这些记录发送到Kafka。数据池任务通过worker进程接收来自Kafka的记录，并将它们写入外部系统。

2.  worker进程

    是连接器和任务的“容器”。负责处理HTTP请求，这些请求用于定义连接器和连接器的配置，还负责保存连接器的配置、启动连接器和连接器任务，并把配置信息传递给任务。如果一个worker进程停止工作或者发生崩溃，集群的其他worker进程会感知到，并将崩溃进程的连接器和任务重新分配给其他进程。如果有新的进程加入集群，其他进程也会感知到，并将自己的连接器和任务分配给新的进程，确保工作负载的均衡。进程还负责提交偏移量，如果任务抛出异常，可以基于这些偏移量进行重试。

3.  转化器和Connect的数据模型

    源连接器负责基于Data API生成数据对象，worker进程通过合适的转化器将数据保存到Kafka。目标连接器也同样。从Kafka读取数据时，worker进程使用指定的转换器将各种格式的数据转换成Data API格式的对象，然后将它们传给目标连接器，目标连接器再将它们插入到目标系统。

4.  偏移量管理

    源连接器返回给worker进程的记录包含一个逻辑分区和逻辑偏移量。这是源系统的分区和偏移量。worker进程会把这些偏移量存储在kafka的一个主题里面。



## 跨集群数据镜像

